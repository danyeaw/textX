{
    "docs": [
        {
            "location": "/",
            "text": "textX\n is a meta-language (i.e. a\nlanguage for language definition) for domain-specific language (DSL)\nspecification in Python.\n\n\nIn a nutshell, textX will help you build your textual language in an easy way.\nYou can invent your own language or build a support for already existing\ntextual language or file format.\n\n\nFrom a single grammar description textX automatically builds a meta-model (in\nthe form of Python classes) and a parser for your language. Parser will parse\nexpressions on your language and automatically build a graph of Python objects\n(i.e. the model) corresponding to the meta-model.\n\n\ntextX is inspired by \nXtext\n - a Java based\nlanguage workbench for building DSLs with full tooling support (editors,\ndebuggers etc.) on Eclipse platform.  If you like Java and\n\nEclipse\n check it out. It is a great tool.\n\n\nFeature highlights\n\n\n\n\n\n\nMeta-model/parser from a single description\n\n\nA single description is used to define both language concrete syntax and its\nmeta-model (a.k.a. abstract syntax). See the description of\n\ngrammar\n and \nmetamodel\n.\n\n\n\n\n\n\nAutomatic model (AST) construction\n\n\nParse tree will be automatically transformed to a graph of python objects\n(a.k.a. the model). See the \nmodel\n section.\n\n\nPython classes will be created by textX but if needed a user supplied\nclasses may be used. See \ncustom classes\n.\n\n\n\n\n\n\nAutomatic linking\n\n\nYou can have a references to other objects in your language and the textual\nrepresentation of the reference will be resolved to proper python reference\nautomatically.\n\n\n\n\n\n\nAutomatic parent-child relationships\n\n\ntextX will maintain a parent-child relationships imposed by the grammar.\nSee \nparent-child relationships\n.\n\n\n\n\n\n\nParser control\n\n\nParser can be configured with regard to case handling, whitespace handling,\nkeyword handling etc. See \nparser\nconfiguration\n.\n\n\n\n\n\n\nModel/object post-processing\n\n\nA callbacks (so called processors) can be registered for models and\nindividual classes.  This enables model/object postprocessing (validation,\nadditional changes etc.).  See \nprocessors\n section.\n\n\n\n\n\n\nGrammar modularization - imports\n\n\nGrammar can be split out in multiple files and than files/grammars can be\nimported where needed. See \nGrammar\nmodularization\n.\n\n\n\n\n\n\nMeta-model/model visualization\n\n\nBoth meta-model and parsed models can be visulized using\n\nGraphViz\n software package. See\n\nvisualization\n section.\n\n\n\n\n\n\nInstallation\n\n\npip install textX\n\n\n\nYou should see an output similar to this:\n\n\nCollecting textx\n  Downloading textX-0.4.2.tar.gz\nCollecting Arpeggio (from textx)\n  Downloading Arpeggio-1.1.tar.gz\nBuilding wheels for collected packages: textx, Arpeggio\n  Running setup.py bdist_wheel for textx\n  Stored in directory: /home/igor/.cache/pip/wheels/b7/d9/ab/05ac4d429fb9c424e8610e295d564e6f0482d2bf772efbb3be\n  Running setup.py bdist_wheel for Arpeggio\n  Stored in directory: /home/igor/.cache/pip/wheels/31/0c/fa/864d57518f97af0a57a71cc124c556af5c965580181204cab3\nSuccessfully built textx Arpeggio\nInstalling collected packages: Arpeggio, textx\nSuccessfully installed Arpeggio-1.1 textx-0.4.2\n\n\n\nTo verify that the library is properly run:\n\n\n$ python -c 'import textx'\n\n\n\nIf there is no error textX is properly installed.\n\n\nGetting started\n\n\nSee textX \nTutorials\n to get you started:\n\n\n\n\nHello World\n\n\nRobot\n\n\nEntity\n\n\n\n\nFor specific information read various \nUser Guide\n sections.\n\n\nAlso, you can\ncheck out \nexamples\n.\n\n\nOpen-source projects using textX\n\n\n\n\napplang\n - Textual DSL for generating mobile applications\n\n\npyTabs\n - A Domain-Specific Language (DSL) for simplified music notation\n\n\npyFlies\n - DSL for cognitive experiments modeling\n\n\n\n\ntextX in the industry\n\n\nTyphoon HIL, Inc.\n is a technology leader for\nultra-high fidelity Hardware-in-the-Loop (HIL) real-time emulators for power\nelectronics.  textX is used as a part of Typhoon-HIL's schematic editor for the\ndescription of power electronic and DSP schemes and components.\n\n\nEditor/IDE support\n\n\nIf you are a vim editor user check out \nsupport for vim\n.\n\n\nIf you are more of an IDE type check out \ntextX-ninja project\n.",
            "title": "Home"
        },
        {
            "location": "/#feature-highlights",
            "text": "Meta-model/parser from a single description  A single description is used to define both language concrete syntax and its\nmeta-model (a.k.a. abstract syntax). See the description of grammar  and  metamodel .    Automatic model (AST) construction  Parse tree will be automatically transformed to a graph of python objects\n(a.k.a. the model). See the  model  section.  Python classes will be created by textX but if needed a user supplied\nclasses may be used. See  custom classes .    Automatic linking  You can have a references to other objects in your language and the textual\nrepresentation of the reference will be resolved to proper python reference\nautomatically.    Automatic parent-child relationships  textX will maintain a parent-child relationships imposed by the grammar.\nSee  parent-child relationships .    Parser control  Parser can be configured with regard to case handling, whitespace handling,\nkeyword handling etc. See  parser\nconfiguration .    Model/object post-processing  A callbacks (so called processors) can be registered for models and\nindividual classes.  This enables model/object postprocessing (validation,\nadditional changes etc.).  See  processors  section.    Grammar modularization - imports  Grammar can be split out in multiple files and than files/grammars can be\nimported where needed. See  Grammar\nmodularization .    Meta-model/model visualization  Both meta-model and parsed models can be visulized using GraphViz  software package. See visualization  section.",
            "title": "Feature highlights"
        },
        {
            "location": "/#installation",
            "text": "pip install textX  You should see an output similar to this:  Collecting textx\n  Downloading textX-0.4.2.tar.gz\nCollecting Arpeggio (from textx)\n  Downloading Arpeggio-1.1.tar.gz\nBuilding wheels for collected packages: textx, Arpeggio\n  Running setup.py bdist_wheel for textx\n  Stored in directory: /home/igor/.cache/pip/wheels/b7/d9/ab/05ac4d429fb9c424e8610e295d564e6f0482d2bf772efbb3be\n  Running setup.py bdist_wheel for Arpeggio\n  Stored in directory: /home/igor/.cache/pip/wheels/31/0c/fa/864d57518f97af0a57a71cc124c556af5c965580181204cab3\nSuccessfully built textx Arpeggio\nInstalling collected packages: Arpeggio, textx\nSuccessfully installed Arpeggio-1.1 textx-0.4.2  To verify that the library is properly run:  $ python -c 'import textx'  If there is no error textX is properly installed.",
            "title": "Installation"
        },
        {
            "location": "/#getting-started",
            "text": "See textX  Tutorials  to get you started:   Hello World  Robot  Entity   For specific information read various  User Guide  sections.  Also, you can\ncheck out  examples .",
            "title": "Getting started"
        },
        {
            "location": "/#open-source-projects-using-textx",
            "text": "applang  - Textual DSL for generating mobile applications  pyTabs  - A Domain-Specific Language (DSL) for simplified music notation  pyFlies  - DSL for cognitive experiments modeling",
            "title": "Open-source projects using textX"
        },
        {
            "location": "/#textx-in-the-industry",
            "text": "Typhoon HIL, Inc.  is a technology leader for\nultra-high fidelity Hardware-in-the-Loop (HIL) real-time emulators for power\nelectronics.  textX is used as a part of Typhoon-HIL's schematic editor for the\ndescription of power electronic and DSP schemes and components.",
            "title": "textX in the industry"
        },
        {
            "location": "/#editoride-support",
            "text": "If you are a vim editor user check out  support for vim .  If you are more of an IDE type check out  textX-ninja project .",
            "title": "Editor/IDE support"
        },
        {
            "location": "/grammar/",
            "text": "textX grammar\n\n\nLanguage syntax and meta-model are defined by textX grammar given as a set of\ntextX rules.\n\n\nRules\n\n\nThe basic building blocks of the textX language are rules. Rule is written\nin the following form:\n\n\nHello:\n  'hello' who=ID;\n;\n\n\n\nThis rule is called \nHello\n. After the name is a colon. Between the colon and\nthe semicolon at the end is a body of the rule given as textX expression. This\nrule tells us that the pattern of \nHello\n objects in the input string consists\nof the word \nhello\n followed by the ID rule (here ID is a rule reference to the\nbuiltin rule, more about this in a moment).\n\n\nThese are valid \nHello\n objects:\n\n\nhello Alice\nhello Bob\nhello foo1234\n\n\n\nRule \nHello\n at the same time defines a Python class \nHello\n. When the rule is\nrecognized in the input stream an object of this class will get created and the\nattribute \nwho\n will be set to whatever the rule \nID\n has matched after the word\n\nhello\n (this is specified by the assignment \nwho=ID\n).\n\n\nOf course, there are many more rule expressions than shown in this small example.\nIn the next section a detailed description of each textX expression is given.\n\n\ntextX base types\n\n\nIn the previous example you have seen an \nID\n rule. This rule is a part of\nbuilt-in rules that form the base of textX type system. Base types/rules are\ngiven in the following figure:\n\n\n\n\n\n\nID\n rule will match an common identifier consisting of letters, digits\n  and underscores. The regex pattern that describe this rule is \n'[^\\d\\W]\\w*\\b'\n.\n  This match will be converted to a python string.\n\n\nINT\n rule will match an integer number. This match will be converted to\n  python \nint\n type.\n\n\nFLOAT\n rule will match a float number. This match will be converted to\n  python \nfloat\n type.\n\n\nBOOL\n rule will match words \ntrue\n or \nfalse\n. This match\n  will be converted to python \nbool\n type.\n\n\nSTRING\n rule will match a quoted string. This match will be converted\n  to python \nstr\n type.\n\n\n\n\nBuilt-in types are automatically converted to python types during object\ninstantiation. See\n\nauto-initialization\n for more information.\n\n\nRule expressions\n\n\nRule expressions is a body of the rule. It is specified using basic expressions\nand operators.\n\n\nThe basic expressions are:\n\n\n\n\nSequence\n\n\nOrdered choice (\n|\n)\n\n\nOptional (\n?\n)\n\n\n\n\nRepetitions\n\n\n\n\nZero or more (\n*\n)\n\n\nOne or more (\n+\n)\n\n\n\n\n\n\n\n\nAssignments\n\n\n\n\nPlain (\n=\n)\n\n\nBoolean (\n?=\n)\n\n\nZero or more (\n*=\n)\n\n\nOne or more (\n+=\n)\n\n\n\n\n\n\n\n\nMatches\n\n\n\n\nString match (\n'...'\n)\n\n\nRegex match (\n/.../\n)\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\nMatch reference\n\n\nLink reference (\n[..]\n)\n\n\n\n\n\n\n\n\nSequence\n\n\nSequence is the simplest textX expression that is given by just writing\ncontained sub-expressions one after another. For example the following rule:\n\n\nColors:\n  \"red\" \"green\" \"blue\"\n;\n\n\n\nis defined as a sequence consisting of three string matches (\nred\n\n\ngreen\n and \nblue\n). Contained expressions will be matched in the\nexact order they are given. If some of the expressions does not match the\nsequence as a whole will fail. The above rule defined by the sequence will match\nonly the following string:\n\n\nred green blue\n\n\n\n\n\nNote\n\n\nIf whitespace skipping is included (which is default) arbitrary whitespaces\ncan occur between matched words.\n\n\n\n\nOrdered choice\n\n\nOrdered choice is given as a set of expression separated by \n|\n operator.\nThis operator will try to match contained expression from left to right and the\nfirst match that succeeds will be used.\n\n\nExample:\n\n\nColor:\n  \"red\" | \"green\" | \"blue\"\n;\n\n\n\nThis will match either \nred\n or \ngreen\n or \nblue\n and the parser will try the\nmatch in that order.\n\n\n\n\nNote\n\n\nIn most classic parsing technologies an unordered match (alternative) is used\nwhich may lead to ambiguous grammar where multiple parse tree may exist for\nthe same input string.\n\n\n\n\nUnderlaying parsing technology of textX is \n\nArpeggio\n which is parser based on\nPEG grammars and thus the \n|\n operator directly translates to Arpeggio's\nPEG ordered choice. Using ordered choice yield unambiguous parsing. If the text\nparses there is only one parse tree possible.\n\n\nOptional\n\n\nOptional\n is an expression that will match contained expression if it can but\nwill not failed otherwise. Thus, optional expression always succeeds.\n\n\nExample:\n\n\nMoveUp:\n  'up' INT?\n;\n\n\n\nINT\n match is optional in this example. This means that the \nup\n keyword is\nrequired but afterwards and integer may be found but it doesn't have to.\n\n\nFollowing lines will match:\n\n\nup 45\nup 1\nup\n\n\n\nOptional expression can be more complex. For example:\n\n\nMoveUp:\n  'up' ( INT | FLOAT )?\n\n\n\nNow, an ordered choice in parentheses is optional.\n\n\nRepetitions\n\n\n\n\n\n\nZero or more\n repetition is specified by \n*\n operator and will match\n  the contained expression zero or more times. Here is an example:\n\n\nColors:\n  (\"red\"|\"green\"|\"blue\")*\n;\n\n\n\nIn this example \nzero or more\n repetition is applied on the \nordered choice\n.\nIn each repeated match one color will be matched trying out from left to\nright.  Thus, \nColors\n rule will match color as many as possible but\nwill not fail if no color exists in the input string. The following would be\nmatched by \nColors\n rule:\n\n\nred blue green\n\n\n\nbut also:\n\n\nred blue blue red red green\n\n\n\nor empty string.\n\n\n\n\n\n\nOne or more\n repetition is specified by \n+\n operator and will match the\n  contained expression one or more times. Thus, everything that is written for\n  \nzero or more\n applies here except that at least one match must be found for\n  this expression to succeed. Here is an above example modified to match at\n  least one color:\n\n\nColors:\n  (\"red\"|\"green\"|\"blue\")+\n;\n\n\n\n\n\n\n\nAssignments\n\n\nAssignment is used as a part of the meta-model deduction process. Each\nassignment will result in an attribute of the meta-class created by the rule.\n\n\nEach assignment consists of LHS (left-hand side) and RHS (right-hand side). The\nLHS is always a name of the meta-class attribute while the RHS can be a\nreference to other rule (either a match or link reference) or a simple match\n(string or regex match). For example:\n\n\nPerson:\n  name=Name ',' surename=Surename ',' age=INT ',' height=INT ';'\n;\n\n\n\nThe \nName\n and \nSurename\n rules referenced in the RHS of the first two\nassignments are not given in this example.\n\n\nThis example describes rule and meta-class \nPerson\n that will parse and\ninstantiate \nPerson\n objects with four attributes:\n\n\n\n\nname\n - which will use rule \nName\n to match the input and the\n  \nname\n will be a reference to the instance of \nName\n class,\n\n\nsurename\n - will use \nSurename\n rule to match the input,\n\n\nage\n - will use builtin type \nINT\n to match a number from the\n  input string. \nage\n will be converted to python \nint\n type.\n\n\nheight\n - the same as \nage\n but the matched number will be\n  assigned to \nheight\n attribute of the \nPerson\n instance.\n\n\n\n\nNotice the comma as the separator between matches and the semicolon match at the\nend of the rule. Those matches must be found in the input but the matched\nstrings will be discarded. They represent a syntactic noise.\n\n\nIf the RHS is one of textX BASETYPEs than the matched string will be converted\nto some of plain python types (e.g. \nint\n, \nstring\n, \nboolean\n).\n\n\nIf RHS is string or regex match like in this example:\n\n\nColor:\n  color=/\\w+/\n;\n\n\n\nthen the attribute given by LHS will be set to be the string matched by the RHS\nregular expression or string.\n\n\nIf the RHS is a reference to other rule than the attribute given by the LHS will\nbe set to refer to the object created by the RHS rule.\n\n\nFollowing strings are matched by the \nPerson\n rule from above:\n\n\nPetar, Petrovic, 27, 185;\nJohn, Doe, 34, 178;\n\n\n\nThere are four types of assignments:\n\n\n\n\n\n\nPlain assignment\n (\n=\n) will match its RHS once and assign what is\n  matched to the attribute given by LHS. The above example uses plain\n  assignments.\n\n\nExamples:\n\n\na=INT\nb=FLOAT\nc=/[a-Z0-9]+/\ndir=Direction\n\n\n\n\n\n\n\nBoolean assignment\n (\n?=\n) will set the attribute on \nTrue\n if\n  the RHS match succeeds or \nFalse\n otherwise.\n\n\nExamples::\n\n\ncold ?= 'cold'\nnumber_given ?= INT\n\n\n\n\n\n\n\nZero or more assignment\n (\n*=\n) - LHS attribute will be a\n  \nlist\n. This assignment will match RHS as long as match succeeds and\n  each matched object will be appended to the attribute. If no match succeeds\n  attribute will be an empty list.\n\n\nExamples::\n\n\ncommands*=Command\nnumbers*=INT\n\n\n\n\n\n\n\nOne or more assignment\n (\n+=\n) - same as previous but must match RHS\n  at least once. If no match succeeds this assignment does not succeeds.\n\n\n\n\n\n\nMatches\n\n\nMatch expression are, besides base type rules, the expression at the lowest\nlevel. They are the basic building blocks for more complex expressions. These\nexpressions will consume input on success.\n\n\nThere are two types of match expressions:\n\n\n\n\n\n\nString match\n - is written as a single quoted string. It will match literal\n  string on the input.\n\n\nHere are a few examples of string matches:\n\n\n'blue'\n'zero'\n'person'\n\n\n\n\n\n\n\nRegex match\n - uses regular expression defined inside \n/ /\n to match\n  input. Therefore, it defines a whole class of strings that can be matched.\n  Internally a python \nre\n module is used.\n\n\nHere are few example of regex matches:\n\n\n/\\s*/\n/[-\\w]*\\b/\n/[^}]*/\n\n\n\n\n\n\n\nReferences\n\n\nRules can reference each other. References are usually used as a\nRHS of the assignments. There are two types of rule references:\n\n\n\n\n\n\nMatch rule reference\n - will \ncall\n other rule. When instance of the called\n  rule is created it will be assigned to the attribute on the LHS. We say that\n  referred object is contained inside referring object (e.g. they form a\n  \nparent-child relationship\n.\n\n\nExample::\n\n\nStructure:\n  'structure' '{'\n    elements*=StructureElement\n  '}'\n;\n\n\n\nStructureElement\n will be matched zero or more times. With each match a new\ninstance of \nStructureElement\n will be created and appended to \nelements\n\npython list. A \nparent\n attribute of each \nStructureElement\n will be set to\nthe containing \nStructure\n.\n\n\n\n\n\n\nLink rule reference\n - will match an identifier of some class object at the\n  given place and convert that identifier to python reference to target object.\n  This reference resolving is done automatically by textX. By default a\n  \nname\n attribute is used as an identifier of the object. Currently,\n  there is no automatic support for name spaces in textX. All objects of the\n  same class are in a single namespace.\n\n\nExample:\n\n\nScreenType:\n  'screen' name=ID \"{\"\n  '}'\n;\n\nScreenInstance:\n  'screen' type=[ScreenType]\n;\n\n\n\nThe \ntype\n attribute is a link to \nScreenType\n object. This is a valid\nusage:\n\n\n// This is definition of ScreenType object\nscreen Introduction {\n\n}\n\n// And this is reference link to the above ScreenType object\n// ScreenInstance instance\nscreen Introduction\n\n\n\nIntroduction\n will be matched, the \nScreenType\n object with that name will\nbe found and \ntype\n attribute of \nScreenInstance\n instance will be set to\nit.\n\n\nID\n rule is used by default to match link identifier. If you want to change\nthat you can use the following syntax:\n\n\nScreenInstance:\n  'screen' type=[ScreenType|WORD]\n;\n\n\n\nHere, instead of \nID\n a \nWORD\n rule is used to match object identifier.\n\n\n\n\n\n\nRepetition modifiers\n\n\nRepetition modifiers are used for the modification of repetition expressions\n(\n*\n, \n+\n, \n*=\n, \n+=\n). They are specified in brackets \n[  ]\n. If there are more\nmodifiers they are separated by a comma.\n\n\nCurrently there are two modifiers defined:\n\n\n\n\n\n\nSeparator modifier\n - is used to define separator on multiple matches.\n  Separator is simple match (string match or regex match).\n\n\nExample:\n\n\nnumbers*=INT[',']\n\n\n\nHere a separator string match is defined (\n','\n). This will match zero\nor more integers separated by commas.\n\n\n45, 47, 3, 78\n\n\n\nA regex can be specified as a separator.\n\n\nfields += ID[/;|,|:/]\n\n\n\nThis will match IDs separated by either \n;\n or \n,\n or \n:\n.\n\n\nfirst, second; third, fourth: fifth\n\n\n\n\n\n\n\nEnd-of-line terminate modifier\n (\neolterm\n) - used to terminate repetition\n  on end-of-line. By default repetition match will span lines. When this\n  modifier is specified repetition will work inside current line only.\n\n\nExample:\n\n\nSTRING*[',', eolterm]\n\n\n\nHere we have separator as well as \neolterm\n defined. This will match\nzero or more strings separated by commas inside one line.\n\n\n\"first\", \"second\", \"third\"\n\"fourth\"\n\n\n\nIf we run example expression once on this string it will match first line only.\n\n\"fourth\"\n in the second line will not be matched.\n\n\n\n\n\n\n\n\nWarning\n\n\nBe aware that when \neolterm\n modifier is used its effect starts from\nprevious match. For example:\n\n\nConditions:\n  'conditions' '{'\n    varNames+=WORD[eolterm]    // match var names until end of line\n  '}'\n\n\n\nIn this example \nvarNames\n must be matched in the same line with\n\nconditions {\n because \neolterm\n effect start immediately.\nIn this example we wanted to give user freedom to specify var names on\nthe next line, even to put some empty lines if he/she wish. In order to do\nthat we should modify example like this::\n\n\nConditions:\n  'conditions' '{'\n    /\\s*/\n    varNames+=WORD[eolterm]    // match var names until end of line\n  '}'\n\n\n\nRegex match \n/\\s*/\n will collect whitespaces (spaces and new-lines)\nbefore \nWORD\n match begins. Afterwards, repeated matches will work\ninside one line only.\n\n\n\n\nRule types\n\n\nThere are three kinds of rules in textX:\n\n\n\n\nCommon rules (or just rules)\n\n\nAbstract rules\n\n\nMatch rules\n\n\n\n\nCommon rules\n are rules that contains at least one assignment, i.e., they\nhave attributes defined. For example:\n\n\nInitialCommand:\n  'initial' x=INT ',' y=INT\n;\n\n\n\nThis rule have two attributes defined: \nx\n and \ny\n.\n\n\nAbstract rules\n are rules that have no assignments and reference at least one\nabstract or common rule. They are usually given as an ordered choice of other\nrules and they are used to generalize other rules. For example:\n\n\nProgram:\n  'begin'\n    commands*=Command\n  'end'\n;\n\nCommand:\n  MoveCommand | InitialCommand\n;\n\n\n\nIn this example, Python objects in \ncommands\n list will be either instances of\n\nMoveCommand\n or \nInitialCommand\n.  \nCommand\n rule is abstract.  A meta-class of\nthis rule will never be instantiated. Abstract rule can also be used in link\nrule references:\n\n\nListOfCommands:\n  commands*=[Command][',']\n;\n\n\n\nAbstract rules may reference match rules and base types. For example:\n\n\nValue:\n    STRING | FLOAT | BOOL | Object | Array | \"null\"\n;\n\n\n\nIn this example base types as well as string match \n\"null\"\n are all match rules\nbut \nObject\n and \nArray\n are common rules and therefore \nValue\n is abstract.\n\n\nAbstract rules can be a complex mix of rule references and match expressions as\nlong as there is at least one abstract or common reference.\nFor example:\n\n\nValue:\n  'id' /\\d+-\\d+/ | FLOAT | Object\n;\n\n\n\nRule with a single reference to abstract or common rule is also abstract:\n\n\nValue:\n  OtherRule\n;\n\n\n\nMatch rules\n are rules that have no assignments either direct or indirect,\ni.e. all referenced rules are match rules too. It is usually used to specify\nenumerated values or some complex string matches that can't be done with regular\nexpressions.\n\n\nExamples:\n\n\nWidget:\n  \"edit\"|\"combo\"|\"checkbox\"|\"togglebutton\"\n;\n\nName:\n  STRING|/(\\w|\\+|-)+/\n;\n\nValue:\n  /(\\w|\\+|-)+/ | FLOAT | INT\n;\n\n\n\nThese rules can be used in match references only (i.e., you can't link to these\nrules as they don't exists as objects), and they produce objects of base python\ntypes (\nstr\n, \nint\n, \nbool\n, \nfloat\n).\n\n\nAll base type rules (e.g., \nINT\n, \nSTRING\n, \nBASETYPE\n) are match rules.\n\n\nRule modifiers\n\n\nRule modifiers are used for  the modification of rules expression. They are\nspecified in brackets (\n[  ]\n) at the beginning of the rule definition after the\nrule name. Currently, they are used to alter parser configuration for whitespace\nhandling on the rule level.\n\n\nThere are two rule modifier at the moment:\n\n\n\n\n\n\nskipws, noskipws\n - are used to enable/disable whitespace skipping during\n  parsing. This will change global parser \nskipws\n setting given during\n  meta-model instantiation.\n\n\nExample:\n\n\nRule:\n    'entity' name=ID /\\s*/ call=Rule2;\nRule2[noskipws]:\n    'first' 'second';\n\n\n\nIn this example \nRule\n rule will use default parser behavior set during\nmeta-model instantiation while \nRule2\n rule will disable whitespace\nskipping. This will change \nRule2\n to match the word \nfirstsecond\n but not\nwords \nfirst second\n with whitespaces in between.\n\n\n\n\nNote\n\n\nRemember that whitespace handling modification will start immediately\nafter previous match. In the above example, additional \n/\\s*/\n is given\nbefore \nRule2\n call to consume all whitespaces before trying to match\n\nRule2\n.\n\n\n\n\n\n\n\n\nws\n - used to redefine what is considered to be a whitespaces on the rule\n  level. textX by default treat space, tab and new-line as a whitespace\n  characters. This can be changed globally during meta-model instantiation (see\n  \nWhitespace handling\n) or per rule using \n  this modifier.\n\n\nExample:\n\n\nRule:\n    'entity' name=ID /\\s*/ call=Rule2;\nRule2[ws='\\n']:\n    'first' 'second';\n\n\n\nIn this example \nRule\n will use default parser behavior but the\n\nRule2\n will alter the white-space definition to be new-line only.\nThis means that the words \nfirst\n and \nsecond\n will get matched\nonly if they are on separate lines or in the same line but without other\ncharacters in between (even tabs and spaces).\n\n\n\n\nNote\n\n\nAs in previous example the modification will start immediately so if you\nwant to consume preceding spaces you must do that explicitely as given\nwith \n/\\s*/\n in the :\nRule\n.\n\n\n\n\n\n\n\n\nGrammar comments\n\n\nSyntax for comments inside grammar is \n//\n for line comments and\n\n/* ... */\n for block comments.\n\n\nLanguage comments\n\n\nTo support comments in your DSL use a special grammar rule \nComment\n.\ntextX will try to match this rule in between each other normal grammar match\n(similar to whitespace matching).\nIf the match succeeds the matched content will be discarded.\n\n\nFor example, in the \nrobot language example\n comments are\ndefined like this:\n\n\nComment:\n  /\\/\\/.*$/\n;\n\n\n\nWhich states that everything starting with \n//\n and continuing until the\nend of line is a comment.\n\n\nGrammar modularization\n\n\nGrammars can be defined in multiple files and than imported. Rules used in\nreferences are first searched in current file and than in imported files in the\norder of import.\n\n\nExample:\n\n\nimport scheme\n\nLibrary:\n  'library' name=Name '{'\n    attributes*=LibraryAttribute\n\n    scheme=Scheme\n\n  '}'\n;\n\n\n\nScheme\n rule is defined in \nscheme.tx\n grammar file imported at the beginning.\n\n\nGrammar files may be located in folders. In that case dot notation is used.\n\n\nExample:\n\n\nimport component.types\n\n\n\ntypes.tx\n grammar is located in \ncomponent\n folder relatively from current\ngrammar file.\n\n\nIf you want to override default search order you can specify fully qualified\nname of the rule using dot notation when giving the name of the referring\nobject.\n\n\nExample:\n\n\nimport component.types\n\nMyRule:\n  a = component.types.List\n;\n\nList:\n  '[' values+=BASETYPE[','] ']'\n;\n\n\n\nList\n from \ncomponent.types\n is matched/instantiated and set to \na\n attribute.",
            "title": "Grammar"
        },
        {
            "location": "/grammar/#textx-grammar",
            "text": "Language syntax and meta-model are defined by textX grammar given as a set of\ntextX rules.",
            "title": "textX grammar"
        },
        {
            "location": "/grammar/#rules",
            "text": "The basic building blocks of the textX language are rules. Rule is written\nin the following form:  Hello:\n  'hello' who=ID;\n;  This rule is called  Hello . After the name is a colon. Between the colon and\nthe semicolon at the end is a body of the rule given as textX expression. This\nrule tells us that the pattern of  Hello  objects in the input string consists\nof the word  hello  followed by the ID rule (here ID is a rule reference to the\nbuiltin rule, more about this in a moment).  These are valid  Hello  objects:  hello Alice\nhello Bob\nhello foo1234  Rule  Hello  at the same time defines a Python class  Hello . When the rule is\nrecognized in the input stream an object of this class will get created and the\nattribute  who  will be set to whatever the rule  ID  has matched after the word hello  (this is specified by the assignment  who=ID ).  Of course, there are many more rule expressions than shown in this small example.\nIn the next section a detailed description of each textX expression is given.",
            "title": "Rules"
        },
        {
            "location": "/grammar/#textx-base-types",
            "text": "In the previous example you have seen an  ID  rule. This rule is a part of\nbuilt-in rules that form the base of textX type system. Base types/rules are\ngiven in the following figure:    ID  rule will match an common identifier consisting of letters, digits\n  and underscores. The regex pattern that describe this rule is  '[^\\d\\W]\\w*\\b' .\n  This match will be converted to a python string.  INT  rule will match an integer number. This match will be converted to\n  python  int  type.  FLOAT  rule will match a float number. This match will be converted to\n  python  float  type.  BOOL  rule will match words  true  or  false . This match\n  will be converted to python  bool  type.  STRING  rule will match a quoted string. This match will be converted\n  to python  str  type.   Built-in types are automatically converted to python types during object\ninstantiation. See auto-initialization  for more information.",
            "title": "textX base types"
        },
        {
            "location": "/grammar/#rule-expressions",
            "text": "Rule expressions is a body of the rule. It is specified using basic expressions\nand operators.  The basic expressions are:   Sequence  Ordered choice ( | )  Optional ( ? )   Repetitions   Zero or more ( * )  One or more ( + )     Assignments   Plain ( = )  Boolean ( ?= )  Zero or more ( *= )  One or more ( += )     Matches   String match ( '...' )  Regex match ( /.../ )     References   Match reference  Link reference ( [..] )",
            "title": "Rule expressions"
        },
        {
            "location": "/grammar/#sequence",
            "text": "Sequence is the simplest textX expression that is given by just writing\ncontained sub-expressions one after another. For example the following rule:  Colors:\n  \"red\" \"green\" \"blue\"\n;  is defined as a sequence consisting of three string matches ( red  green  and  blue ). Contained expressions will be matched in the\nexact order they are given. If some of the expressions does not match the\nsequence as a whole will fail. The above rule defined by the sequence will match\nonly the following string:  red green blue   Note  If whitespace skipping is included (which is default) arbitrary whitespaces\ncan occur between matched words.",
            "title": "Sequence"
        },
        {
            "location": "/grammar/#ordered-choice",
            "text": "Ordered choice is given as a set of expression separated by  |  operator.\nThis operator will try to match contained expression from left to right and the\nfirst match that succeeds will be used.  Example:  Color:\n  \"red\" | \"green\" | \"blue\"\n;  This will match either  red  or  green  or  blue  and the parser will try the\nmatch in that order.   Note  In most classic parsing technologies an unordered match (alternative) is used\nwhich may lead to ambiguous grammar where multiple parse tree may exist for\nthe same input string.   Underlaying parsing technology of textX is  Arpeggio  which is parser based on\nPEG grammars and thus the  |  operator directly translates to Arpeggio's\nPEG ordered choice. Using ordered choice yield unambiguous parsing. If the text\nparses there is only one parse tree possible.",
            "title": "Ordered choice"
        },
        {
            "location": "/grammar/#optional",
            "text": "Optional  is an expression that will match contained expression if it can but\nwill not failed otherwise. Thus, optional expression always succeeds.  Example:  MoveUp:\n  'up' INT?\n;  INT  match is optional in this example. This means that the  up  keyword is\nrequired but afterwards and integer may be found but it doesn't have to.  Following lines will match:  up 45\nup 1\nup  Optional expression can be more complex. For example:  MoveUp:\n  'up' ( INT | FLOAT )?  Now, an ordered choice in parentheses is optional.",
            "title": "Optional"
        },
        {
            "location": "/grammar/#repetitions",
            "text": "Zero or more  repetition is specified by  *  operator and will match\n  the contained expression zero or more times. Here is an example:  Colors:\n  (\"red\"|\"green\"|\"blue\")*\n;  In this example  zero or more  repetition is applied on the  ordered choice .\nIn each repeated match one color will be matched trying out from left to\nright.  Thus,  Colors  rule will match color as many as possible but\nwill not fail if no color exists in the input string. The following would be\nmatched by  Colors  rule:  red blue green  but also:  red blue blue red red green  or empty string.    One or more  repetition is specified by  +  operator and will match the\n  contained expression one or more times. Thus, everything that is written for\n   zero or more  applies here except that at least one match must be found for\n  this expression to succeed. Here is an above example modified to match at\n  least one color:  Colors:\n  (\"red\"|\"green\"|\"blue\")+\n;",
            "title": "Repetitions"
        },
        {
            "location": "/grammar/#assignments",
            "text": "Assignment is used as a part of the meta-model deduction process. Each\nassignment will result in an attribute of the meta-class created by the rule.  Each assignment consists of LHS (left-hand side) and RHS (right-hand side). The\nLHS is always a name of the meta-class attribute while the RHS can be a\nreference to other rule (either a match or link reference) or a simple match\n(string or regex match). For example:  Person:\n  name=Name ',' surename=Surename ',' age=INT ',' height=INT ';'\n;  The  Name  and  Surename  rules referenced in the RHS of the first two\nassignments are not given in this example.  This example describes rule and meta-class  Person  that will parse and\ninstantiate  Person  objects with four attributes:   name  - which will use rule  Name  to match the input and the\n   name  will be a reference to the instance of  Name  class,  surename  - will use  Surename  rule to match the input,  age  - will use builtin type  INT  to match a number from the\n  input string.  age  will be converted to python  int  type.  height  - the same as  age  but the matched number will be\n  assigned to  height  attribute of the  Person  instance.   Notice the comma as the separator between matches and the semicolon match at the\nend of the rule. Those matches must be found in the input but the matched\nstrings will be discarded. They represent a syntactic noise.  If the RHS is one of textX BASETYPEs than the matched string will be converted\nto some of plain python types (e.g.  int ,  string ,  boolean ).  If RHS is string or regex match like in this example:  Color:\n  color=/\\w+/\n;  then the attribute given by LHS will be set to be the string matched by the RHS\nregular expression or string.  If the RHS is a reference to other rule than the attribute given by the LHS will\nbe set to refer to the object created by the RHS rule.  Following strings are matched by the  Person  rule from above:  Petar, Petrovic, 27, 185;\nJohn, Doe, 34, 178;  There are four types of assignments:    Plain assignment  ( = ) will match its RHS once and assign what is\n  matched to the attribute given by LHS. The above example uses plain\n  assignments.  Examples:  a=INT\nb=FLOAT\nc=/[a-Z0-9]+/\ndir=Direction    Boolean assignment  ( ?= ) will set the attribute on  True  if\n  the RHS match succeeds or  False  otherwise.  Examples::  cold ?= 'cold'\nnumber_given ?= INT    Zero or more assignment  ( *= ) - LHS attribute will be a\n   list . This assignment will match RHS as long as match succeeds and\n  each matched object will be appended to the attribute. If no match succeeds\n  attribute will be an empty list.  Examples::  commands*=Command\nnumbers*=INT    One or more assignment  ( += ) - same as previous but must match RHS\n  at least once. If no match succeeds this assignment does not succeeds.",
            "title": "Assignments"
        },
        {
            "location": "/grammar/#matches",
            "text": "Match expression are, besides base type rules, the expression at the lowest\nlevel. They are the basic building blocks for more complex expressions. These\nexpressions will consume input on success.  There are two types of match expressions:    String match  - is written as a single quoted string. It will match literal\n  string on the input.  Here are a few examples of string matches:  'blue'\n'zero'\n'person'    Regex match  - uses regular expression defined inside  / /  to match\n  input. Therefore, it defines a whole class of strings that can be matched.\n  Internally a python  re  module is used.  Here are few example of regex matches:  /\\s*/\n/[-\\w]*\\b/\n/[^}]*/",
            "title": "Matches"
        },
        {
            "location": "/grammar/#references",
            "text": "Rules can reference each other. References are usually used as a\nRHS of the assignments. There are two types of rule references:    Match rule reference  - will  call  other rule. When instance of the called\n  rule is created it will be assigned to the attribute on the LHS. We say that\n  referred object is contained inside referring object (e.g. they form a\n   parent-child relationship .  Example::  Structure:\n  'structure' '{'\n    elements*=StructureElement\n  '}'\n;  StructureElement  will be matched zero or more times. With each match a new\ninstance of  StructureElement  will be created and appended to  elements \npython list. A  parent  attribute of each  StructureElement  will be set to\nthe containing  Structure .    Link rule reference  - will match an identifier of some class object at the\n  given place and convert that identifier to python reference to target object.\n  This reference resolving is done automatically by textX. By default a\n   name  attribute is used as an identifier of the object. Currently,\n  there is no automatic support for name spaces in textX. All objects of the\n  same class are in a single namespace.  Example:  ScreenType:\n  'screen' name=ID \"{\"\n  '}'\n;\n\nScreenInstance:\n  'screen' type=[ScreenType]\n;  The  type  attribute is a link to  ScreenType  object. This is a valid\nusage:  // This is definition of ScreenType object\nscreen Introduction {\n\n}\n\n// And this is reference link to the above ScreenType object\n// ScreenInstance instance\nscreen Introduction  Introduction  will be matched, the  ScreenType  object with that name will\nbe found and  type  attribute of  ScreenInstance  instance will be set to\nit.  ID  rule is used by default to match link identifier. If you want to change\nthat you can use the following syntax:  ScreenInstance:\n  'screen' type=[ScreenType|WORD]\n;  Here, instead of  ID  a  WORD  rule is used to match object identifier.",
            "title": "References"
        },
        {
            "location": "/grammar/#repetition-modifiers",
            "text": "Repetition modifiers are used for the modification of repetition expressions\n( * ,  + ,  *= ,  += ). They are specified in brackets  [  ] . If there are more\nmodifiers they are separated by a comma.  Currently there are two modifiers defined:    Separator modifier  - is used to define separator on multiple matches.\n  Separator is simple match (string match or regex match).  Example:  numbers*=INT[',']  Here a separator string match is defined ( ',' ). This will match zero\nor more integers separated by commas.  45, 47, 3, 78  A regex can be specified as a separator.  fields += ID[/;|,|:/]  This will match IDs separated by either  ;  or  ,  or  : .  first, second; third, fourth: fifth    End-of-line terminate modifier  ( eolterm ) - used to terminate repetition\n  on end-of-line. By default repetition match will span lines. When this\n  modifier is specified repetition will work inside current line only.  Example:  STRING*[',', eolterm]  Here we have separator as well as  eolterm  defined. This will match\nzero or more strings separated by commas inside one line.  \"first\", \"second\", \"third\"\n\"fourth\"  If we run example expression once on this string it will match first line only. \"fourth\"  in the second line will not be matched.     Warning  Be aware that when  eolterm  modifier is used its effect starts from\nprevious match. For example:  Conditions:\n  'conditions' '{'\n    varNames+=WORD[eolterm]    // match var names until end of line\n  '}'  In this example  varNames  must be matched in the same line with conditions {  because  eolterm  effect start immediately.\nIn this example we wanted to give user freedom to specify var names on\nthe next line, even to put some empty lines if he/she wish. In order to do\nthat we should modify example like this::  Conditions:\n  'conditions' '{'\n    /\\s*/\n    varNames+=WORD[eolterm]    // match var names until end of line\n  '}'  Regex match  /\\s*/  will collect whitespaces (spaces and new-lines)\nbefore  WORD  match begins. Afterwards, repeated matches will work\ninside one line only.",
            "title": "Repetition modifiers"
        },
        {
            "location": "/grammar/#rule-types",
            "text": "There are three kinds of rules in textX:   Common rules (or just rules)  Abstract rules  Match rules   Common rules  are rules that contains at least one assignment, i.e., they\nhave attributes defined. For example:  InitialCommand:\n  'initial' x=INT ',' y=INT\n;  This rule have two attributes defined:  x  and  y .  Abstract rules  are rules that have no assignments and reference at least one\nabstract or common rule. They are usually given as an ordered choice of other\nrules and they are used to generalize other rules. For example:  Program:\n  'begin'\n    commands*=Command\n  'end'\n;\n\nCommand:\n  MoveCommand | InitialCommand\n;  In this example, Python objects in  commands  list will be either instances of MoveCommand  or  InitialCommand .   Command  rule is abstract.  A meta-class of\nthis rule will never be instantiated. Abstract rule can also be used in link\nrule references:  ListOfCommands:\n  commands*=[Command][',']\n;  Abstract rules may reference match rules and base types. For example:  Value:\n    STRING | FLOAT | BOOL | Object | Array | \"null\"\n;  In this example base types as well as string match  \"null\"  are all match rules\nbut  Object  and  Array  are common rules and therefore  Value  is abstract.  Abstract rules can be a complex mix of rule references and match expressions as\nlong as there is at least one abstract or common reference.\nFor example:  Value:\n  'id' /\\d+-\\d+/ | FLOAT | Object\n;  Rule with a single reference to abstract or common rule is also abstract:  Value:\n  OtherRule\n;  Match rules  are rules that have no assignments either direct or indirect,\ni.e. all referenced rules are match rules too. It is usually used to specify\nenumerated values or some complex string matches that can't be done with regular\nexpressions.  Examples:  Widget:\n  \"edit\"|\"combo\"|\"checkbox\"|\"togglebutton\"\n;\n\nName:\n  STRING|/(\\w|\\+|-)+/\n;\n\nValue:\n  /(\\w|\\+|-)+/ | FLOAT | INT\n;  These rules can be used in match references only (i.e., you can't link to these\nrules as they don't exists as objects), and they produce objects of base python\ntypes ( str ,  int ,  bool ,  float ).  All base type rules (e.g.,  INT ,  STRING ,  BASETYPE ) are match rules.",
            "title": "Rule types"
        },
        {
            "location": "/grammar/#rule-modifiers",
            "text": "Rule modifiers are used for  the modification of rules expression. They are\nspecified in brackets ( [  ] ) at the beginning of the rule definition after the\nrule name. Currently, they are used to alter parser configuration for whitespace\nhandling on the rule level.  There are two rule modifier at the moment:    skipws, noskipws  - are used to enable/disable whitespace skipping during\n  parsing. This will change global parser  skipws  setting given during\n  meta-model instantiation.  Example:  Rule:\n    'entity' name=ID /\\s*/ call=Rule2;\nRule2[noskipws]:\n    'first' 'second';  In this example  Rule  rule will use default parser behavior set during\nmeta-model instantiation while  Rule2  rule will disable whitespace\nskipping. This will change  Rule2  to match the word  firstsecond  but not\nwords  first second  with whitespaces in between.   Note  Remember that whitespace handling modification will start immediately\nafter previous match. In the above example, additional  /\\s*/  is given\nbefore  Rule2  call to consume all whitespaces before trying to match Rule2 .     ws  - used to redefine what is considered to be a whitespaces on the rule\n  level. textX by default treat space, tab and new-line as a whitespace\n  characters. This can be changed globally during meta-model instantiation (see\n   Whitespace handling ) or per rule using \n  this modifier.  Example:  Rule:\n    'entity' name=ID /\\s*/ call=Rule2;\nRule2[ws='\\n']:\n    'first' 'second';  In this example  Rule  will use default parser behavior but the Rule2  will alter the white-space definition to be new-line only.\nThis means that the words  first  and  second  will get matched\nonly if they are on separate lines or in the same line but without other\ncharacters in between (even tabs and spaces).   Note  As in previous example the modification will start immediately so if you\nwant to consume preceding spaces you must do that explicitely as given\nwith  /\\s*/  in the : Rule .",
            "title": "Rule modifiers"
        },
        {
            "location": "/grammar/#grammar-comments",
            "text": "Syntax for comments inside grammar is  //  for line comments and /* ... */  for block comments.",
            "title": "Grammar comments"
        },
        {
            "location": "/grammar/#language-comments",
            "text": "To support comments in your DSL use a special grammar rule  Comment .\ntextX will try to match this rule in between each other normal grammar match\n(similar to whitespace matching).\nIf the match succeeds the matched content will be discarded.  For example, in the  robot language example  comments are\ndefined like this:  Comment:\n  /\\/\\/.*$/\n;  Which states that everything starting with  //  and continuing until the\nend of line is a comment.",
            "title": "Language comments"
        },
        {
            "location": "/grammar/#grammar-modularization",
            "text": "Grammars can be defined in multiple files and than imported. Rules used in\nreferences are first searched in current file and than in imported files in the\norder of import.  Example:  import scheme\n\nLibrary:\n  'library' name=Name '{'\n    attributes*=LibraryAttribute\n\n    scheme=Scheme\n\n  '}'\n;  Scheme  rule is defined in  scheme.tx  grammar file imported at the beginning.  Grammar files may be located in folders. In that case dot notation is used.  Example:  import component.types  types.tx  grammar is located in  component  folder relatively from current\ngrammar file.  If you want to override default search order you can specify fully qualified\nname of the rule using dot notation when giving the name of the referring\nobject.  Example:  import component.types\n\nMyRule:\n  a = component.types.List\n;\n\nList:\n  '[' values+=BASETYPE[','] ']'\n;  List  from  component.types  is matched/instantiated and set to  a  attribute.",
            "title": "Grammar modularization"
        },
        {
            "location": "/metamodel/",
            "text": "textX meta-models\n\n\ntextX meta-model is a Python object that knows about all classes that can be\ninstantiated while parsing input. A meta-model is built from the grammar by\nthe functions \nmetamodel_from_file\n or \nmetamodel_from_str\n in the\n\ntextx.metamodel\n module.\n\n\nfrom textx.metamodel import metamodel_from_file\nmy_metamodel = metamodel_from_file('my_grammar.tx')\n\n\n\nEach rule from the grammar will result in a Python class kept in a meta-model.\nBesides, meta-model knows how to parse input strings and convert them to\n\nmodel\n.\n\n\nParsing input and creating model is done by \nmodel_from_file\n and\n\nmodel_from_str\n methods of the meta-model object:\n\n\nmy_model = my_metamodel.model_from_file('some_input.md')\n\n\n\nCustom classes\n\n\nFor each grammar rule a Python class with the same name is created dynamically.\nThese classes are instantiated during parsing of input string/file to create\na graph of python objects, a.k.a. \nmodel\n or Abstract-Syntax Tree (AST).\n\n\nMost of the time dynamically created classes will be sufficient but sometimes\nyou will want to use your own classes instead. To do so use parameter \nclasses\n\nduring meta-model instantiation. This parameter is a list of your classes that\nshould be named the same as the rules from the grammar which they represent.\n\n\nfrom textx.metamodel import metamodel_from_str\n\ngrammar = '''\nEntityModel:\n  entities+=Entity    // each model has one or more entities\n;\n\nEntity:\n  'entity' name=ID '{'\n    attributes+=Attribute     // each entity has one or more attributes\n  '}'\n;\n\nAttribute:\n  name=ID ':' type=[Entity]   // type is a reference to an entity. There are\n                              // built-in entities registered on the meta-model\n                              // for primitive types (integer, string)\n;\n'''\n\nclass Entity(object):\n  def __init__(self, parent, name, attributes):\n    self.parent = parent\n    self.name = name\n    self.attributes = attributes\n\n\n# Use our Entity class. \"Attribute\" class will be created dynamically.\nentity_mm = metamodel_from_str(grammar, classes=[Entity])\n\n\n\nNow \nentity_mm\n can be used to parse input models where our \nEntity\n class will\nbe instantiated to represent each \nEntity\n rule from the grammar.\n\n\n\n\nNote\n\n\nConstructor of user classes should accept all attributes defined by the\ncorresponding rule from the grammar. In the previous example we have provided\n\nname\n and \nattributes\n attributes from the \nEntity\n rule.\nIf the class is a child in parent-child relationship (see in the next\nsection) then \nparent\n constructor parameter should also be given.\n\n\n\n\nParent-child relationships\n\n\nThere is often an intrinsic parent-child relationship between object in the\nmodel. In the previous example each \nAttribute\n instance will always be a child\nof some \nEntity\n object.\n\n\ntextX gives automatic support for these relationships by providing \nparent\n\nattribute on each child object.\n\n\nWhen you navigate \nmodel\n each child instance will have a \nparent\n\nattribute.\n\n\n\n\nNote\n\n\nAlways provide parent parameter in user classes for each class that is a\nchild in parent-child relationship.\n\n\n\n\nProcessors\n\n\nTo specify static semantics of the language textX uses a concept called\n\nprocessor\n. Processors are python callable that can modify model elements\nduring model parsing/instantiation or do some additional checks that are not\npossible to do by the grammar alone.\n\n\nThere are two types of processors:\n\n\n\n\nmodel processors\n - are callable that are called at the end of the parsing\n  when the whole model is instantiated. These processors accepts meta-model and\n  model as parameters.\n\n\nobject processors\n - are registered for particular classes (grammar rules)\n  and are called when the objects of the given class is instantiated.\n\n\n\n\nProcessors can modify model/objects or raise exception (\nTextXSemanticError\n) if\nsome constraint is not met. User code that call model instantiation/parsing can\ncatch and handle those exception.\n\n\nModel processors\n\n\nTo register model processor call \nregister_model_processor\n on the meta-model\ninstance.\n\n\nfrom textx.metamodel import metamodel_from_file\n\n# Model processor is a callable that will accept meta-model and model as its\n# parameters.\ndef check_some_semantics(metamodel, model):\n  ...\n  ... Do some check on the model and raise TextXSemanticError if semantics\n  ... rules are violated.\n\nmy_metamodel = metamodel_from_file('mygrammar.tx')\n\n# Register model processor on meta-model instance\nmy_metamodel.register_model_processor(check_some_semantics)\n\n# Parse model. check_some_semantics will be called automatically after\n# successful parse to do further checks. If the rules are not met\n# an instance of TextXSemanticError will be raised.\nmy_metamodel.model_from_file('some_model.ext')\n\n\n\nObject processors\n\n\nThe purpose of object processors is the same as for model processors but they\nare called as soon as the particular object is recognized in the input string.\nThey are registered per class/rule.\n\n\nLet's do some additional checks for the above Entity DSL example.\n\n\ndef entity_obj_processor(entity):\n  '''\n  Check that Entity names are capitalized. This could also be specified\n  in the grammar using regex match but we will do that check here just\n  as an example.\n  '''\n\n  if entity.name != entity.name.capitalize():\n    raise TextXSemanticError('Entity name \"%s\" must be capitalized.' %\n                            entity.name)\n\ndef attribute_obj_processor(attribute):\n  '''\n  Obj. processors can also introduce changes in the objects they process.\n  Here we set \"primitive\" attribute based on the Entity they refer to.\n  '''\n  attribute.primitive = attribute.type.name in ['integer', 'string']\n\n\n# Object processors are registered by defining a map between a rule name\n# and the callable that will process the instances of that rule/class.\nobj_processors = {\n    'Entity': entity_obj_processor,\n    'Attribute': attribute_obj_processor,\n    }\n\n# This map/dict is registered on a meta-model by the \"register_obj_processors\"\n# call.\nentity_mm.register_obj_processors(obj_processors)\n\n# Parse model. At each successful parse of Entity or Attribute the registered\n# processor will be called and the semantics error will be raised if the\n# check do not pass.\nentity_mm.model_from_file('my_entity_model.ent')\n\n\n\nFor another example usage of object processor that modify objects see object\nprocessor \nmove_command_processor\n \nrobot example\n.\n\n\nBuilt-in objects\n\n\nOften you will need objects that should be a part of each model and you do not\nwant users to specify them in every model they create. Most notable example is\nprimitive types (e.g. \ninteger\n, \nstring\n, \nbool\n).\n\n\nLet's provide \ninteger\n and \nstring\n Entities to our \nEntity\n meta-model in\norder to simplify model creation so that user can use the names of these two\nentities for \nAttribute\n types.\n\n\nclass Entity(object):\n    def __init__(self, parent, name, attributes):\n        self.parent = parent\n        self.name = name\n        self.attributes = attributes\n\nentity_builtins = {\n        'integer': Entity(None, 'integer', []),\n        'string': Entity(None, 'string', [])\n}\nentity_mm = metamodel_from_file(\n  'entity.tx',\n  classes=[Entity]            # Register Entity user class,\n  builtins=entity_builtins    # Register integer and string built-in objs\n)\n\n\n\nNow an \ninteger\n and \nstring\n \nAttribute\n type can be used.  See\n\nmodel\n and \nEntitiy\n example for more.\n\n\nAuto-initialization of attributes\n\n\nEach object that is recognized in the input string will be instantiated and\ntheir attributes will be set to the values parsed from the input. In the event\nthat defined attribute is optional, it will nevertheless be created on the\ninstance and set to the default value.\n\n\nHere is a list of default values for each base textX type:\n\n\n\n\nID - empty string - ''\n\n\nINT - int - 0\n\n\nFLOAT - float - 0.0\n\n\nBOOL - bool - False\n\n\nSTRING - empty string - ''\n\n\n\n\nEach attribute with zero or more multiplicity (\n*=\n) that does not match any\nobject from the input will be initialized to an empty list.\n\n\nAttribute declared with one or more multiplicity (\n+=\n) must match at least one\nobject from the input and therefore will be transformed to python list\ncontaining all matched objects.\n\n\nThe drawback of this auto-initialization system is that we can't be sure if\nthe attribute was missing from the input or was matched but the value was\ndefault.\n\n\nIn some applications it is important to distinguish between those two\nsituations. For that purpose there is a parameter \nauto_init_attributes\n to the\nmeta-model constructor that is by default \nTrue\n but can be set to \nFalse\n to\nprevent auto-initialization to take place.\n\n\nIf auto-initialization is disabled than each optional attribute that was not\nmatched on the input will be set to \nNone\n.  This holds true for plain\nassignments (\n=\n). An optional assignment (\n?=\n) will always be \nFalse\n if the\nRHS object is not matched in the input. Many multiplicity assignments (\n*=\n and\n\n+=\n) will always be python lists.\n\n\nParser configuration\n\n\nCase sensitivity\n\n\nParser is by default case sensitive. For DSLs that should be case insensitive\nuse \nignore_case\n parameter to the meta-model constructor call.\n\n\nfrom textx.metamodel import metamodel_from_file\n\nmy_metamodel = metamodel_from_file('mygrammar.tx', ignore_case=True)\n\n\n\n\nWhitespace handling\n\n\nThe parser will skip whitespaces by default. Whitespaces are spaces, tabs and\nnewlines by default. Skipping of whitespaces can be disabled by \nskipws\n bool\nparameter in constructor call. Also, what is a whitespace can be redefined by\n\nws\n string parameter.\n\n\nfrom textx.metamodel import metamodel_from_file\nmy_metamodel = metamodel_from_file('mygrammar.tx', skipws=False, ws='\\s\\n')\n\n\n\n\nWhitespaces and whitespace skipping can be defined in the grammar on the level\nof a single rule by \nrule modifiers\n.\n\n\nAutomatic keywords\n\n\nWhen designing a DSL it is usually desirable to match keywords on word\nboundaries.  For example, if we have Entity grammar from the above than a word\n\nentity\n will be considered a keyword and should be matched on word boundaries\nonly. If we have a word \nentity2\n in the input string at the place where\n\nentity\n should be matched the match should not succeed.\n\n\nWe could achieve this by using regular expression match and word boundaries\nregular expression rule for each keyword-like match.\n\n\nEnitity:\n  /\\bentity\\b/ name=ID ...\n\n\n\nBut the grammar will be cumbersome to read.\n\n\ntextX can do automatic word boundary match for all keyword-like string matches.\nTo enable this feature set parameter \nautokwd\n to \nTrue\n in the constructor\ncall.\n\n\nfrom textx.metamodel import metamodel_from_file\nmy_metamodel = metamodel_from_file('mygrammar.tx', autokwd=True)\n\n\n\n\nA keyword is considered any simple match from the grammar that is matched by the\nregular expression \n[^\\d\\W]\\w*\n.",
            "title": "Meta-model"
        },
        {
            "location": "/metamodel/#textx-meta-models",
            "text": "textX meta-model is a Python object that knows about all classes that can be\ninstantiated while parsing input. A meta-model is built from the grammar by\nthe functions  metamodel_from_file  or  metamodel_from_str  in the textx.metamodel  module.  from textx.metamodel import metamodel_from_file\nmy_metamodel = metamodel_from_file('my_grammar.tx')  Each rule from the grammar will result in a Python class kept in a meta-model.\nBesides, meta-model knows how to parse input strings and convert them to model .  Parsing input and creating model is done by  model_from_file  and model_from_str  methods of the meta-model object:  my_model = my_metamodel.model_from_file('some_input.md')",
            "title": "textX meta-models"
        },
        {
            "location": "/metamodel/#custom-classes",
            "text": "For each grammar rule a Python class with the same name is created dynamically.\nThese classes are instantiated during parsing of input string/file to create\na graph of python objects, a.k.a.  model  or Abstract-Syntax Tree (AST).  Most of the time dynamically created classes will be sufficient but sometimes\nyou will want to use your own classes instead. To do so use parameter  classes \nduring meta-model instantiation. This parameter is a list of your classes that\nshould be named the same as the rules from the grammar which they represent.  from textx.metamodel import metamodel_from_str\n\ngrammar = '''\nEntityModel:\n  entities+=Entity    // each model has one or more entities\n;\n\nEntity:\n  'entity' name=ID '{'\n    attributes+=Attribute     // each entity has one or more attributes\n  '}'\n;\n\nAttribute:\n  name=ID ':' type=[Entity]   // type is a reference to an entity. There are\n                              // built-in entities registered on the meta-model\n                              // for primitive types (integer, string)\n;\n'''\n\nclass Entity(object):\n  def __init__(self, parent, name, attributes):\n    self.parent = parent\n    self.name = name\n    self.attributes = attributes\n\n\n# Use our Entity class. \"Attribute\" class will be created dynamically.\nentity_mm = metamodel_from_str(grammar, classes=[Entity])  Now  entity_mm  can be used to parse input models where our  Entity  class will\nbe instantiated to represent each  Entity  rule from the grammar.   Note  Constructor of user classes should accept all attributes defined by the\ncorresponding rule from the grammar. In the previous example we have provided name  and  attributes  attributes from the  Entity  rule.\nIf the class is a child in parent-child relationship (see in the next\nsection) then  parent  constructor parameter should also be given.",
            "title": "Custom classes"
        },
        {
            "location": "/metamodel/#parent-child-relationships",
            "text": "There is often an intrinsic parent-child relationship between object in the\nmodel. In the previous example each  Attribute  instance will always be a child\nof some  Entity  object.  textX gives automatic support for these relationships by providing  parent \nattribute on each child object.  When you navigate  model  each child instance will have a  parent \nattribute.   Note  Always provide parent parameter in user classes for each class that is a\nchild in parent-child relationship.",
            "title": "Parent-child relationships"
        },
        {
            "location": "/metamodel/#processors",
            "text": "To specify static semantics of the language textX uses a concept called processor . Processors are python callable that can modify model elements\nduring model parsing/instantiation or do some additional checks that are not\npossible to do by the grammar alone.  There are two types of processors:   model processors  - are callable that are called at the end of the parsing\n  when the whole model is instantiated. These processors accepts meta-model and\n  model as parameters.  object processors  - are registered for particular classes (grammar rules)\n  and are called when the objects of the given class is instantiated.   Processors can modify model/objects or raise exception ( TextXSemanticError ) if\nsome constraint is not met. User code that call model instantiation/parsing can\ncatch and handle those exception.",
            "title": "Processors"
        },
        {
            "location": "/metamodel/#model-processors",
            "text": "To register model processor call  register_model_processor  on the meta-model\ninstance.  from textx.metamodel import metamodel_from_file\n\n# Model processor is a callable that will accept meta-model and model as its\n# parameters.\ndef check_some_semantics(metamodel, model):\n  ...\n  ... Do some check on the model and raise TextXSemanticError if semantics\n  ... rules are violated.\n\nmy_metamodel = metamodel_from_file('mygrammar.tx')\n\n# Register model processor on meta-model instance\nmy_metamodel.register_model_processor(check_some_semantics)\n\n# Parse model. check_some_semantics will be called automatically after\n# successful parse to do further checks. If the rules are not met\n# an instance of TextXSemanticError will be raised.\nmy_metamodel.model_from_file('some_model.ext')",
            "title": "Model processors"
        },
        {
            "location": "/metamodel/#object-processors",
            "text": "The purpose of object processors is the same as for model processors but they\nare called as soon as the particular object is recognized in the input string.\nThey are registered per class/rule.  Let's do some additional checks for the above Entity DSL example.  def entity_obj_processor(entity):\n  '''\n  Check that Entity names are capitalized. This could also be specified\n  in the grammar using regex match but we will do that check here just\n  as an example.\n  '''\n\n  if entity.name != entity.name.capitalize():\n    raise TextXSemanticError('Entity name \"%s\" must be capitalized.' %\n                            entity.name)\n\ndef attribute_obj_processor(attribute):\n  '''\n  Obj. processors can also introduce changes in the objects they process.\n  Here we set \"primitive\" attribute based on the Entity they refer to.\n  '''\n  attribute.primitive = attribute.type.name in ['integer', 'string']\n\n\n# Object processors are registered by defining a map between a rule name\n# and the callable that will process the instances of that rule/class.\nobj_processors = {\n    'Entity': entity_obj_processor,\n    'Attribute': attribute_obj_processor,\n    }\n\n# This map/dict is registered on a meta-model by the \"register_obj_processors\"\n# call.\nentity_mm.register_obj_processors(obj_processors)\n\n# Parse model. At each successful parse of Entity or Attribute the registered\n# processor will be called and the semantics error will be raised if the\n# check do not pass.\nentity_mm.model_from_file('my_entity_model.ent')  For another example usage of object processor that modify objects see object\nprocessor  move_command_processor   robot example .",
            "title": "Object processors"
        },
        {
            "location": "/metamodel/#built-in-objects",
            "text": "Often you will need objects that should be a part of each model and you do not\nwant users to specify them in every model they create. Most notable example is\nprimitive types (e.g.  integer ,  string ,  bool ).  Let's provide  integer  and  string  Entities to our  Entity  meta-model in\norder to simplify model creation so that user can use the names of these two\nentities for  Attribute  types.  class Entity(object):\n    def __init__(self, parent, name, attributes):\n        self.parent = parent\n        self.name = name\n        self.attributes = attributes\n\nentity_builtins = {\n        'integer': Entity(None, 'integer', []),\n        'string': Entity(None, 'string', [])\n}\nentity_mm = metamodel_from_file(\n  'entity.tx',\n  classes=[Entity]            # Register Entity user class,\n  builtins=entity_builtins    # Register integer and string built-in objs\n)  Now an  integer  and  string   Attribute  type can be used.  See model  and  Entitiy  example for more.",
            "title": "Built-in objects"
        },
        {
            "location": "/metamodel/#auto-initialization-of-attributes",
            "text": "Each object that is recognized in the input string will be instantiated and\ntheir attributes will be set to the values parsed from the input. In the event\nthat defined attribute is optional, it will nevertheless be created on the\ninstance and set to the default value.  Here is a list of default values for each base textX type:   ID - empty string - ''  INT - int - 0  FLOAT - float - 0.0  BOOL - bool - False  STRING - empty string - ''   Each attribute with zero or more multiplicity ( *= ) that does not match any\nobject from the input will be initialized to an empty list.  Attribute declared with one or more multiplicity ( += ) must match at least one\nobject from the input and therefore will be transformed to python list\ncontaining all matched objects.  The drawback of this auto-initialization system is that we can't be sure if\nthe attribute was missing from the input or was matched but the value was\ndefault.  In some applications it is important to distinguish between those two\nsituations. For that purpose there is a parameter  auto_init_attributes  to the\nmeta-model constructor that is by default  True  but can be set to  False  to\nprevent auto-initialization to take place.  If auto-initialization is disabled than each optional attribute that was not\nmatched on the input will be set to  None .  This holds true for plain\nassignments ( = ). An optional assignment ( ?= ) will always be  False  if the\nRHS object is not matched in the input. Many multiplicity assignments ( *=  and += ) will always be python lists.",
            "title": "Auto-initialization of attributes"
        },
        {
            "location": "/metamodel/#parser-configuration",
            "text": "",
            "title": "Parser configuration"
        },
        {
            "location": "/metamodel/#case-sensitivity",
            "text": "Parser is by default case sensitive. For DSLs that should be case insensitive\nuse  ignore_case  parameter to the meta-model constructor call.  from textx.metamodel import metamodel_from_file\n\nmy_metamodel = metamodel_from_file('mygrammar.tx', ignore_case=True)",
            "title": "Case sensitivity"
        },
        {
            "location": "/metamodel/#whitespace-handling",
            "text": "The parser will skip whitespaces by default. Whitespaces are spaces, tabs and\nnewlines by default. Skipping of whitespaces can be disabled by  skipws  bool\nparameter in constructor call. Also, what is a whitespace can be redefined by ws  string parameter.  from textx.metamodel import metamodel_from_file\nmy_metamodel = metamodel_from_file('mygrammar.tx', skipws=False, ws='\\s\\n')  Whitespaces and whitespace skipping can be defined in the grammar on the level\nof a single rule by  rule modifiers .",
            "title": "Whitespace handling"
        },
        {
            "location": "/metamodel/#automatic-keywords",
            "text": "When designing a DSL it is usually desirable to match keywords on word\nboundaries.  For example, if we have Entity grammar from the above than a word entity  will be considered a keyword and should be matched on word boundaries\nonly. If we have a word  entity2  in the input string at the place where entity  should be matched the match should not succeed.  We could achieve this by using regular expression match and word boundaries\nregular expression rule for each keyword-like match.  Enitity:\n  /\\bentity\\b/ name=ID ...  But the grammar will be cumbersome to read.  textX can do automatic word boundary match for all keyword-like string matches.\nTo enable this feature set parameter  autokwd  to  True  in the constructor\ncall.  from textx.metamodel import metamodel_from_file\nmy_metamodel = metamodel_from_file('mygrammar.tx', autokwd=True)  A keyword is considered any simple match from the grammar that is matched by the\nregular expression  [^\\d\\W]\\w* .",
            "title": "Automatic keywords"
        },
        {
            "location": "/model/",
            "text": "textX models\n\n\nModel is a python object graph consisting of POPOs (Plain Old Python Objects)\nconstructed from the input string that conforms to your DSL defined by the\ngrammar and additional \nmodel and object processors\n.\n\n\nIn a sense this structure is an Abstract Syntax Tree (AST) known from classic\nparsing theory but it is actually a graph structure where each reference is\nresolved to a proper python reference.\n\n\nEach object is an instance of a class from meta-model. Classes are created\non-the-fly from grammar rules or are \nsupplied by the\nuser\n.\n\n\nModel is created from input string using \nmodel_from_file\n and \nmodel_from_str\n\nmethods of meta-model instance.\n\n\nfrom textx.metamodel import metamodel_from_file\n\nmy_mm = metamodel_from_file('mygrammar.tx')\n\n# Create model\nmy_model = my_mm.model_from_file('some_model.ext')\n\n\n\nLet's take a Entity language used in \nCustom\nClasses\n section.\n\n\nContent of \nentity.tx\n file:\n\n\nEntityModel:\n  entities+=Entity    // each model has one or more entities\n;\n\nEntity:\n  'entity' name=ID '{'\n    attributes+=Attribute     // each entity has one or more attributes\n  '}'\n;\n\nAttribute:\n  name=ID ':' type=[Entity]   // type is a reference to an entity. There are\n                              // built-in entities registered on the meta-model\n                              // for primitive types (integer, string)\n;\n\n\n\nFor meta-model construction and built-in registration see \nCustom\nClasses\n and\n\nBuiltins\n sections.\n\n\nNow, we can use the \nentity_mm\n meta-model to parse and create Entity models.\n\n\nperson_model = entity_mm.model_from_file('person.ent')\n\n\n\n\nWhere \nperson.ent\n file might contain this:\n\n\nentity Person {\n  name : string\n  address: Address\n  age: integer\n}\n\nentity Address {\n  street : string\n  city : string\n  country : string\n}\n\n\n\nSpecial attributes\n\n\nBeside attributes specified by the grammar each model object has\n\n_tx_position\n attribute that hold the position in the input string where\nthe object has been matched by the parser.\n\n\nThis is an absolute position in the input stream. To convert it to line/column\nformat use \npos_to_linecol\n method of the parser.\n\n\nline, col = entity_mm.parser.pos_to_linecol(\n    person_model.entities[0]._tx_position)\n\n\n\n\nThis will give the line/column position of the first entity.",
            "title": "Model"
        },
        {
            "location": "/model/#textx-models",
            "text": "Model is a python object graph consisting of POPOs (Plain Old Python Objects)\nconstructed from the input string that conforms to your DSL defined by the\ngrammar and additional  model and object processors .  In a sense this structure is an Abstract Syntax Tree (AST) known from classic\nparsing theory but it is actually a graph structure where each reference is\nresolved to a proper python reference.  Each object is an instance of a class from meta-model. Classes are created\non-the-fly from grammar rules or are  supplied by the\nuser .  Model is created from input string using  model_from_file  and  model_from_str \nmethods of meta-model instance.  from textx.metamodel import metamodel_from_file\n\nmy_mm = metamodel_from_file('mygrammar.tx')\n\n# Create model\nmy_model = my_mm.model_from_file('some_model.ext')  Let's take a Entity language used in  Custom\nClasses  section.  Content of  entity.tx  file:  EntityModel:\n  entities+=Entity    // each model has one or more entities\n;\n\nEntity:\n  'entity' name=ID '{'\n    attributes+=Attribute     // each entity has one or more attributes\n  '}'\n;\n\nAttribute:\n  name=ID ':' type=[Entity]   // type is a reference to an entity. There are\n                              // built-in entities registered on the meta-model\n                              // for primitive types (integer, string)\n;  For meta-model construction and built-in registration see  Custom\nClasses  and Builtins  sections.  Now, we can use the  entity_mm  meta-model to parse and create Entity models.  person_model = entity_mm.model_from_file('person.ent')  Where  person.ent  file might contain this:  entity Person {\n  name : string\n  address: Address\n  age: integer\n}\n\nentity Address {\n  street : string\n  city : string\n  country : string\n}",
            "title": "textX models"
        },
        {
            "location": "/model/#special-attributes",
            "text": "Beside attributes specified by the grammar each model object has _tx_position  attribute that hold the position in the input string where\nthe object has been matched by the parser.  This is an absolute position in the input stream. To convert it to line/column\nformat use  pos_to_linecol  method of the parser.  line, col = entity_mm.parser.pos_to_linecol(\n    person_model.entities[0]._tx_position)  This will give the line/column position of the first entity.",
            "title": "Special attributes"
        },
        {
            "location": "/visualization/",
            "text": "Visualization\n\n\nA meta-model, model and parse-tree can be exported to dot files\n(\nGraphViz\n) for visualization. Module \ntextx.export\n\ncontains functions \nmetamodel_export\n and \nmodel_export\n that can export\nmeta-model and model to dot file respectively.\n\n\nIf \ndebugging\n is enabled, meta-model, model and parse trees will\nautomatically get exported to dot.\n\n\nMeta-model visualization\n\n\nTo visualize meta-model (see \nEntity\nexample\n)\ndo:\n\n\nfrom textx.metamodel import metamodel_from_file\nfrom textx.export import metamodel_export\n\nentity_mm = metamodel_from_file('entity.tx')\n\nmetamodel_export(entity_mm, 'entity.dot')\n\n\n\n\nentity.dot\n file will be created. You can visualize this file by a\nvarious dot viewers or can convert it to various image formats by 'dot'\ntool.\n\n\n$ dot -Tpng -O entity.dot\n\n\n\nThe following image is generated:\n\n\n\n\nModel visualization\n\n\nSimilar to meta-model visualization you can visualize your models also (see \nEntity\nexample\n).\n\n\nfrom textx.export import model_export\n\nperson_model = entity_mm.model_from_file('person.ent')\n\nmodel_export(person_model, 'person.dot')\n\n\n\n\nConvert this \ndot\n file to \npng\n with:\n\n\n$ dot -Tpng -O person.dot\n\n\n\nThe following image is generated:\n\n\n\n\n\n\nNote\n\n\nSee also \ntextx command/tool\n for model visualization\nfrom command line.",
            "title": "Visualization"
        },
        {
            "location": "/visualization/#visualization",
            "text": "A meta-model, model and parse-tree can be exported to dot files\n( GraphViz ) for visualization. Module  textx.export \ncontains functions  metamodel_export  and  model_export  that can export\nmeta-model and model to dot file respectively.  If  debugging  is enabled, meta-model, model and parse trees will\nautomatically get exported to dot.",
            "title": "Visualization"
        },
        {
            "location": "/visualization/#meta-model-visualization",
            "text": "To visualize meta-model (see  Entity\nexample )\ndo:  from textx.metamodel import metamodel_from_file\nfrom textx.export import metamodel_export\n\nentity_mm = metamodel_from_file('entity.tx')\n\nmetamodel_export(entity_mm, 'entity.dot')  entity.dot  file will be created. You can visualize this file by a\nvarious dot viewers or can convert it to various image formats by 'dot'\ntool.  $ dot -Tpng -O entity.dot  The following image is generated:",
            "title": "Meta-model visualization"
        },
        {
            "location": "/visualization/#model-visualization",
            "text": "Similar to meta-model visualization you can visualize your models also (see  Entity\nexample ).  from textx.export import model_export\n\nperson_model = entity_mm.model_from_file('person.ent')\n\nmodel_export(person_model, 'person.dot')  Convert this  dot  file to  png  with:  $ dot -Tpng -O person.dot  The following image is generated:    Note  See also  textx command/tool  for model visualization\nfrom command line.",
            "title": "Model visualization"
        },
        {
            "location": "/error_handling/",
            "text": "Error handling\n\n\ntextX will raise an error if syntax or semantic error is detected during\nmeta-model or model parsing/construction.\n\n\nFor syntax error \nTextXSyntaxError\n is raised. For semantic error\n\nTextXSemanticError\n is raised. Both exceptions inherits from \nTextXError\n.\nThese exceptions are located in \ntextx.exceptions\n module.\n\n\nAll exceptions have \nmessage\n attribute with the error message and \nline\n and\n\ncol\n attributes with the line and column where the error is found.\n\n\n\n\nNote\n\n\nSee also \ntextx command/tool\n for (meta)model checking \nfrom command line.",
            "title": "Error handling"
        },
        {
            "location": "/error_handling/#error-handling",
            "text": "textX will raise an error if syntax or semantic error is detected during\nmeta-model or model parsing/construction.  For syntax error  TextXSyntaxError  is raised. For semantic error TextXSemanticError  is raised. Both exceptions inherits from  TextXError .\nThese exceptions are located in  textx.exceptions  module.  All exceptions have  message  attribute with the error message and  line  and col  attributes with the line and column where the error is found.   Note  See also  textx command/tool  for (meta)model checking \nfrom command line.",
            "title": "Error handling"
        },
        {
            "location": "/debugging/",
            "text": "Debugging\n\n\ntextX supports debugging on the meta-model (grammar) and model level. If\ndebugging is enabled textX will print various debugging messages.\n\n\nIf \ndebug\n parameter to meta-model construction is set to \nTrue\n debug messages\nduring grammar parsing and meta-model construction will be printed. Additionally\na parse tree created during grammar parse as well as meta-model (if constructed\nsuccessfully) dot files will be generated:\n\n\nform textx.metamodel import metamodel_from_file\n\nmy_metamodel = metamodel_from_file('mygrammar.tx', debug=True)\n\n\n\n\nIf \ndebug\n is set in the \nmodel_from_file/str\n calls than various\nmessages during model parsing and construction will be printed. Additionally,\nparse tree created from the input as well as model will be exported to dot\nfile.\n\n\n  my_model = my_metamodel.model_from_file('mymodel.mod', debug=True)",
            "title": "Debugging"
        },
        {
            "location": "/debugging/#debugging",
            "text": "textX supports debugging on the meta-model (grammar) and model level. If\ndebugging is enabled textX will print various debugging messages.  If  debug  parameter to meta-model construction is set to  True  debug messages\nduring grammar parsing and meta-model construction will be printed. Additionally\na parse tree created during grammar parse as well as meta-model (if constructed\nsuccessfully) dot files will be generated:  form textx.metamodel import metamodel_from_file\n\nmy_metamodel = metamodel_from_file('mygrammar.tx', debug=True)  If  debug  is set in the  model_from_file/str  calls than various\nmessages during model parsing and construction will be printed. Additionally,\nparse tree created from the input as well as model will be exported to dot\nfile.    my_model = my_metamodel.model_from_file('mymodel.mod', debug=True)",
            "title": "Debugging"
        },
        {
            "location": "/textx_command/",
            "text": "textx command/tool\n\n\nTo check and visualize (meta)models from command line.\n\n\n\n\nUsing the tool\n\n\nTo get basic help:\n\n\n$ textx --help\nusage: textx [-h] [-i] [-d] cmd metamodel [model]\n\ntextX checker and visualizer\n\npositional arguments:\n  cmd         Command - \"check\" or \"visualize\"\n  metamodel   Meta-model file name\n  model       Model file name\n\noptional arguments:\n  -h, --help  show this help message and exit\n  -i          case-insensitive parsing\n  -d          run in debug mode\n\n\n\nYou can check and visualize (generate .dot file) your meta-model or model using\nthis tool.\n\n\nFor example, to check and visualize of metamodel you could issue:\n\n\n$ textx visualize robot.tx\nMeta-model OK.\nGenerating 'robot.tx.dot' file for meta-model.\nTo convert to png run 'dot -Tpng -O robot.tx.dot'\n\n\n\nCreate image from .dot file:\n\n\n$ dot -Tpng -O robot.tx.dot\n\n\n\nVisualize model:\n\n\n$ textx visualize robot.tx program.rbt\nMeta-model OK.\nModel OK.\nGenerating 'robot.tx.dot' file for meta-model.\nTo convert to png run 'dot -Tpng -O robot.tx.dot'\nGenerating 'program.rbt.dot' file for model.\nTo convert to png run 'dot -Tpng -O program.rbt.dot'\n\n\n\nTo only check (meta)models use \ncheck\n command:\n\n\n$ textx check robot.tx program.rbt\n\n\n\nIf there is an error you will get a nice error report:\n\n\n$ textx check robot.tx program.rbt\nMeta-model OK.\nError in model file.\nExpected 'initial' or 'up' or 'down' or 'left' or \n  'right' or 'end' at program.rbt:(3, 3) => 'al 3, 1   *gore 4    '.",
            "title": "textx command"
        },
        {
            "location": "/textx_command/#textx-commandtool",
            "text": "To check and visualize (meta)models from command line.",
            "title": "textx command/tool"
        },
        {
            "location": "/textx_command/#using-the-tool",
            "text": "To get basic help:  $ textx --help\nusage: textx [-h] [-i] [-d] cmd metamodel [model]\n\ntextX checker and visualizer\n\npositional arguments:\n  cmd         Command - \"check\" or \"visualize\"\n  metamodel   Meta-model file name\n  model       Model file name\n\noptional arguments:\n  -h, --help  show this help message and exit\n  -i          case-insensitive parsing\n  -d          run in debug mode  You can check and visualize (generate .dot file) your meta-model or model using\nthis tool.  For example, to check and visualize of metamodel you could issue:  $ textx visualize robot.tx\nMeta-model OK.\nGenerating 'robot.tx.dot' file for meta-model.\nTo convert to png run 'dot -Tpng -O robot.tx.dot'  Create image from .dot file:  $ dot -Tpng -O robot.tx.dot  Visualize model:  $ textx visualize robot.tx program.rbt\nMeta-model OK.\nModel OK.\nGenerating 'robot.tx.dot' file for meta-model.\nTo convert to png run 'dot -Tpng -O robot.tx.dot'\nGenerating 'program.rbt.dot' file for model.\nTo convert to png run 'dot -Tpng -O program.rbt.dot'  To only check (meta)models use  check  command:  $ textx check robot.tx program.rbt  If there is an error you will get a nice error report:  $ textx check robot.tx program.rbt\nMeta-model OK.\nError in model file.\nExpected 'initial' or 'up' or 'down' or 'left' or \n  'right' or 'end' at program.rbt:(3, 3) => 'al 3, 1   *gore 4    '.",
            "title": "Using the tool"
        },
        {
            "location": "/tutorials/hello_world/",
            "text": "Hello World example\n\n\nThis is an example of very simple Hello World like language.\n\n\n\n\nThese are the steps to build a very basic Hello World - like language.\n\n\n\n\n\n\nWrite a language description in textX (file \nhello.tx\n):\n\n\nHelloWorldModel:\n  'hello' to_greet+=Who[',']\n;\n\nWho:\n  name = /[^,]*/\n;\n\n\n\nDescription consists of a set of parsing rules which at the same time\ndescribe Python classes that will be dynamically created and used to\ninstantiate objects of your model.  This small example consists of two\nrules: \nHelloWorldModel\n and \nWho\n.  \nHelloWorldModel\n starts with the\nkeyword \nhello\n after which a one or more \nWho\n object must be written\nseparated by commas. \nWho\n objects will be parsed, instantiated and stored\nin a \nto_greet\n list on a \nHelloWorldModel\n object. \nWho\n objects consists\nonly of its names which must be matched the regular expression rule\n\n/[^,]*/\n (match non-comma zero or more times). Please see \ntextX\ngrammar\n section for more information on writing grammar rules.\n\n\n\n\n\n\nCreate meta-model from textX language description (file \nhello.py\n):\n\n\nfrom textx.metamodel import metamodel_from_file\nhello_meta = metamodel_from_file('hello.tx')\n\n\n\n\n\n\n\nOptionally export meta-model to dot (visualize your language abstract syntax):\n\n\nfrom textx.export import metamodel_export\nmetamodel_export(hello_meta, 'hello_meta.dot')\n\n\n\n\n\nYou can see that for each rule from language description an appropriate\nPython class has been created. A BASETYPE hierarchy is built-in. Each\nmeta-model has it.\n\n\n\n\n\n\nCreate some content (i.e. model) in your new language (\nexample.hello\n):\n\n\nhello World, Solar System, Universe\n\n\n\nYour language syntax is also described by language rules from step 1.\n\n\nIf we break down the text of the example model it looks like this:\n\n\n\n\nWe see that the whole line is a \nHelloWorldModel\n and the parts \nWorld\n, \n\nSolar System\n, and \nUniverse\n are \nWho\n objects. Red coloured text is\nsyntactic noise that is needed by the parser (and programmers) to recognize\nthe boundaries of the objects in the text.\n\n\n\n\n\n\nUse meta-model to create models from textual description:\n\n\nexample_hello_model = hello_meta.model_from_file('example.hello')\n\n\n\nTextual model \u2018example.hello\u2019 will be parsed and transformed to a plain\nPython object graph. Object classes are those defined by the meta-model.\n\n\n\n\n\n\nYou can optionally export model to \ndot\n file to visualize it:\n\n\nfrom textx.export import model_export\nmodel_export(example_hello_model, 'example.dot')\n\n\n\n\n\nThis is an object graph automatically constructed from \nexample.hello\n\nfile.\n\n\nWe see that each \nWho\n object is contained in the python attribute\n\nto_greet\n of list type which is defined by the grammar.\n\n\n\n\n\n\nUse your model: interpret it, generate code \u2026 It is a plain Python\n   graph of objects with plain attributes!\n\n\n\n\n\n\n\n\nNote\n\n\nTry out a \ncomplete tutorial\n for building a simple robot language.",
            "title": "Hello World"
        },
        {
            "location": "/tutorials/hello_world/#hello-world-example",
            "text": "This is an example of very simple Hello World like language.   These are the steps to build a very basic Hello World - like language.    Write a language description in textX (file  hello.tx ):  HelloWorldModel:\n  'hello' to_greet+=Who[',']\n;\n\nWho:\n  name = /[^,]*/\n;  Description consists of a set of parsing rules which at the same time\ndescribe Python classes that will be dynamically created and used to\ninstantiate objects of your model.  This small example consists of two\nrules:  HelloWorldModel  and  Who .   HelloWorldModel  starts with the\nkeyword  hello  after which a one or more  Who  object must be written\nseparated by commas.  Who  objects will be parsed, instantiated and stored\nin a  to_greet  list on a  HelloWorldModel  object.  Who  objects consists\nonly of its names which must be matched the regular expression rule /[^,]*/  (match non-comma zero or more times). Please see  textX\ngrammar  section for more information on writing grammar rules.    Create meta-model from textX language description (file  hello.py ):  from textx.metamodel import metamodel_from_file\nhello_meta = metamodel_from_file('hello.tx')    Optionally export meta-model to dot (visualize your language abstract syntax):  from textx.export import metamodel_export\nmetamodel_export(hello_meta, 'hello_meta.dot')   You can see that for each rule from language description an appropriate\nPython class has been created. A BASETYPE hierarchy is built-in. Each\nmeta-model has it.    Create some content (i.e. model) in your new language ( example.hello ):  hello World, Solar System, Universe  Your language syntax is also described by language rules from step 1.  If we break down the text of the example model it looks like this:   We see that the whole line is a  HelloWorldModel  and the parts  World ,  Solar System , and  Universe  are  Who  objects. Red coloured text is\nsyntactic noise that is needed by the parser (and programmers) to recognize\nthe boundaries of the objects in the text.    Use meta-model to create models from textual description:  example_hello_model = hello_meta.model_from_file('example.hello')  Textual model \u2018example.hello\u2019 will be parsed and transformed to a plain\nPython object graph. Object classes are those defined by the meta-model.    You can optionally export model to  dot  file to visualize it:  from textx.export import model_export\nmodel_export(example_hello_model, 'example.dot')   This is an object graph automatically constructed from  example.hello \nfile.  We see that each  Who  object is contained in the python attribute to_greet  of list type which is defined by the grammar.    Use your model: interpret it, generate code \u2026 It is a plain Python\n   graph of objects with plain attributes!     Note  Try out a  complete tutorial  for building a simple robot language.",
            "title": "Hello World example"
        },
        {
            "location": "/tutorials/robot/",
            "text": "Robot tutorial\n\n\nIn this tutorial we will build a simple robot language to demonstrate\nthe basic workflow when working with textX.\n\n\n\n\nRobot language\n\n\nWhen building a DSL we should first do a domain analysis, to see what concepts\ndo we have and what are their relationships and constraints. In the following\nparagraph a short analysis is done. Important concepts are emphasized.\n\n\nIn this case we want an imperative language that should define robot movement on\nthe imaginary grid.  Robot should \nmove\n in four base \ndirection\n. We will\ncall that direction \nup, down, left\n and \nright\n (you could use north,\nsouth, west and east if you like).  Additionally, we shall have a robot\ncoordinate given in x, y \nposition\n.  For simplicity our robot can move in\ndiscrete \nsteps\n. In each movement robot can move by 1 or more steps but in\nthe same direction. Coordinate is given as a pair of integer numbers. Robot will\nhave an \ninitial position\n. If not given explicitly it is assumed that\nposition is \n(0, 0)\n.\n\n\nSo, lets build a simple robot language.\n\n\nGrammar\n\n\nFirst we need to define a grammar for the language. In textX the grammar will\nalso define a meta-model (a.k.a. abstract syntax) for the language which can be\nvisualized and be used as a part of the documentation.\n\n\nUsually we start by outlining some program in the language we are building.\n\n\nHere is an example of \nprogram\n on robot language:\n\n\nbegin\n    initial 3, 1\n    up 4\n    left 9\n    down\n    right 1\nend\n\n\n\nWe have \nbegin\n and \nend\n keywords that define the beginning and end of the\nprogram. In this case we could do without these keywords but lets have it to\nmake it more interesting.\n\n\nIn between those two keywords we have a sequence of instruction. First\ninstruction will position our robot at coordinate \n(3, 1)\n. After that robot will\nmove \nup 4 steps\n, \nleft 9 steps\n, \ndown 1 step\n (1 step is default) and finally \n1\nstep to the right\n.\n\n\nLets start with grammar definition. We shall start in a top-down manner so lets\nfirst define a program as a whole.\n\n\nProgram:\n  'begin'\n    commands*=Command\n  'end'\n;\n\n\n\nHere we see that our program is defined with sequence of:\n\n\n\n\nstring match (\n'begin'\n),\n\n\nzero or more assignment to \ncommands\n attribute,\n\n\nstring match (\n'end'\n).\n\n\n\n\nString matches will require literal strings given at the begin and end of\nprogram. If this is not satisfied a syntax error will be raised. This whole rule\n(\nProgram\n) will create a class with the same name in the meta-model. Each\nprogram will be an instance of this class. \ncommands\n assignment will result in\na python attribute \ncommands\n on the instance of \nProgram\n class. This attribute\nwill be of Python \nlist\n type (because \n*=\n assignment is used).  Each element\nof this list will be a specific command.\n\n\nNow, we see that we have different types of commands. First command has two\nparameters and it defines the robot initial position. Other commands has one or\nzero parameters and define the robot movement.\n\n\nTo state that some textX rule is specialised in 2 or more rules we use an\nabstract rule. For \nCommand\n we shall define two specializations:\n\nInitialCommand\n and \nMoveCommand\n like this:\n\n\nCommand:\n  InitialCommand | MoveCommand\n;\n\n\n\nAbstract rule is given as ordered choice of other rules. This can be read as\n\nEach command is either a InitialCommand or MoveCommand\n.\n\n\nLets now define command for setting initial position.\n\n\nInitialCommand:\n  'initial' x=INT ',' y=INT\n;\n\n\n\nThis rule specifies a class \nInitialCommand\n in the meta-model. Each initial\nposition command will be an instance of this class.\n\n\nSo, this command should start with the keyword \ninitial\n after which we give an\ninteger number (base type rule \nINT\n - this number will be available as\nattribute \nx\n on the \nInitialCommand\n instance), than a separator \n,\n is\nrequired after which we have \ny\n coordinate as integer number (this will be\navailable as attribute \ny\n). Using base type rule \nINT\n matched number from\ninput string will be automatically converted to python type \nint\n.\n\n\nNow, lets define a movement command. We know that this command consists of\ndirection identifier and optional number of steps (if not given the default will\nbe 1).\n\n\nMoveCommand:\n  direction=Direction (steps=INT)?\n;\n\n\n\nSo, the movement command model object will have two attributes.\n\ndirection\n attribute will define one of the four possible directions and\n\nsteps\n attribute will be an integer that will hold how many steps a robot\nwill move in given direction. Steps are optional so if not given in the program\nit will still be a correct syntax. Notice, that the default of 1 is not\nspecified in the grammar. The grammar deals with syntax constraints. Additional\nsemantics will be handled later in model/object processors (see below).\n\n\nNow, the missing part is \nDirection\n rule referenced from the previous rule.\nThis rule will define what can be written as a direction.  We will define this\nrule like this:\n\n\nDirection:\n  \"up\"|\"down\"|\"left\"|\"right\"\n;\n\n\n\nThis kind of rule is called a \nmatch rule\n. This rule does not result in a new\nobject. It consists of ordered choice of simple matches (string, regex), base\ntype rules (INT, STRING, BOOL...) and/or other match rule references.\n\n\nThe result of this match will be assigned to the attribute from which it was\nreferenced. If base type was used it will be converted in a proper python type.\nIf not, it will be a python string that will contain the text that was matched\nfrom the input.\n\n\nIn this case a one of 4 words will be matched and that string will be assigned\nto the \ndirection\n attribute of the \nMoveCommand\n instance.\n\n\nThe final touch to the grammar is a definition of the comment rule. We want to\ncomment our robot code, right?\n\n\nIn textX a special rule called \nComment\n is used for that purpose.\nLets define a C-style single line comments.\n\n\nComment:\n  /\\/\\/.*$/\n;\n\n\n\nOur grammar is done. Save it in \nrobot.tx\n file. The content of this file should\nnow be:\n\n\nProgram:\n  'begin'\n    commands*=Command\n  'end'\n;\n\nCommand:\n  InitialCommand | MoveCommand\n;\n\nInitialCommand:\n  'initial' x=INT ',' y=INT\n;\n\nMoveCommand:\n  direction=Direction (steps=INT)?\n;\n\nDirection:\n  \"up\"|\"down\"|\"left\"|\"right\"\n;\n\nComment:\n  /\\/\\/.*$/\n;\n\n\n\nNotice that we have not constrained initial position command to be specified\njust once on the beginning of the program. This basically means that this\ncommand can be given multiple times throughout the program. I will leave as an\nexercise to the reader to implement this constraint.\n\n\nInstantiating meta-model\n\n\nIn order to parse our models we first need to construct a meta-model. A\ntextX meta-model is a Python object that contains all classes that can be\ninstantiated in our model. For each grammar rule a class is created.\nAdditionally, meta-model contains a parser that knows how to parse input\nstrings. From parsed input (parse tree) meta-model will create a model.\n\n\nMeta-models are created from our grammar description, in this case\n\nrobot.tx\n file:\n\n\nfrom textx.metamodel import metamodel_from_file\nrobot_mm = metamodel_from_file('robot.tx')\n\n\n\n\nNext step during language design is meta-model visualization. It is usually\neasier to comprehend our language if rendered graphically. To do so we use\nexcellent \nGraphViz\n software package and its DSL for\ngraph specification called \ndot\n. It is a textual language for visual graph\ndefinition.\n\n\nLets export our meta-model to dot language.\n\n\nfrom textx.export import metamodel_export\nmetamodel_export(robot_mm, 'robot_meta.dot')\n\n\n\n\nFirst parameter is our meta-model object while the second is an output dot\nfilename.\n\n\ndot\n file can be opened with dot viewer (there are many to choose from) or\ntransformed with \ndot\n tool to raster or vector graphics.\n\n\nFor example:\n\n\ndot -Tpng robot_meta.dot -O robot_meta.png\n\n\n\nThis command will create \npng\n image out of \ndot\n file.\n\n\n\n\n\n\nNote\n\n\nThis meta-model can be used to parse multiple models.\n\n\n\n\nInstantiating model\n\n\nNow, when we have our meta-model we can parse models from strings or external\ntextual files.\n\n\nrobot_model = robot_mm.model_from_file('program.rbt')\n\n\n\n\nThis command will parse file \nprogram.rbt\n and constructs our robot model.\nIn this file does not match our language a syntax error will be raised on the\nfirst error encountered.\n\n\nIn the same manner as meta-model visualization we can visualize our model too.\n\n\nfrom textx.export import model_export\nmodel_export(robot_model, 'program.dot')\n\n\n\n\nThis will create \nprogram.dot\n file that can be visualized using proper viewer\nor transformed to image.\n\n\ndot -Tpng program.dot -O program.png\n\n\n\nFor the robot program above we should get an image like this:\n\n\n\n\nInterpreting model\n\n\nWhen we have successfully parsed and loaded our model/program (or mogram or\nprodel ;) ) we can do various stuff. Usually what would you like to do is to\ntranslate your program to some other language (Java, Python, C#, Ruby,...) or\nyou could build an interpreter that will evaluate/interpret your model directly.\nOr you could analyse your model, extract informations from it etc. It is up to\nyou to decide.\n\n\nWe will show here how to build a simple interpreter that will start the robot\nfrom the initial position and print the position of the robot after each\ncommand.\n\n\nLets imagine that we have a robot that understands our language.\n\n\nclass Robot(object):\n\n  def __init__(self):\n    # Initial position is (0,0)\n    self.x = 0\n    self.y = 0\n\n  def __str__(self):\n    return \"Robot position is {}, {}.\".format(self.x, self.y)\n\n\n\nNow, our robot will have an \ninterpret\n method that accepts our robot model and\nruns it. At each step this method will update the robot position and print it.\n\n\ndef interpret(self, model):\n\n    # model is an instance of Program\n    for c in model.commands:\n\n        if c.__class__.__name__ == \"InitialCommand\":\n            print(\"Setting position to: {}, {}\".format(c.x, c.y))\n            self.x = c.x\n            self.y = c.y\n        else:\n            dir = c.direction\n            print(\"Going {} for {} step(s).\".format(dir, c.steps))\n\n            move = {\n                \"up\": (0, 1),\n                \"down\": (0, -1),\n                \"left\": (-1, 0),\n                \"right\": (1, 0)\n            }[dir]\n\n            # Calculate new robot position\n            self.x += c.steps * move[0]\n            self.y += c.steps * move[1]\n\n        print(self)\n\n\n\nNow lets give our \nrobot_model\n to \nRobot\n instance and see what happens.\n\n\nrobot = Robot()\nrobot.interpret(robot_model)\n\n\n\n\nYou should get this output:\n\n\nSetting position to: 3, 1\nRobot position is 3, 1.\nGoing up for 4 step(s).\nRobot position is 3, 5.\nGoing left for 9 step(s).\nRobot position is -6, 5.\nGoing down for 0 step(s).\nRobot position is -6, 5.\nGoing right for 1 step(s).\nRobot position is -5, 5.\n\n\n\nIt is \nalmost\n correct. We can see that down movement is for 0 steps because we\nhave not defined the steps for \ndown\n command and haven't done anything yet to\nimplement default of 1.\n\n\nThe best way to implement default value for step is to use so called \nobject\nprocessor\n for \nMoveCommand\n.\nObject processor is a callable that gets called whenever textX parses and\ninstantiates an object of particular class. Use \nregister_obj_processors\n\nmethod on meta-model to register callables/processors for classes your wish to\nprocess in some way immediately after instantiation.\n\n\nLets define our processor for \nMoveCommand\n.\n\n\ndef move_command_processor(move_cmd):\n\n  # If steps is not given, set it do default 1 value.\n  if move_cmd.steps == 0:\n    move_cmd.steps = 1\n\n\n\n\nNow, register this processor on meta-model. After meta-model construction add a\nline for registration.\n\n\nrobot_mm.register_obj_processors({'MoveCommand': move_command_processor})\n\n\n\n\nregister_obj_processors\n accepts a dictionary keyed by class name. The\nvalues are callables that should handle instances of the given class.\n\n\nIf you run robot interpreter again you will get output like this:\n\n\nSetting position to: 3, 1\nRobot position is 3, 1.\nGoing up for 4 step(s).\nRobot position is 3, 5.\nGoing left for 9 step(s).\nRobot position is -6, 5.\nGoing down for 1 step(s).\nRobot position is -6, 4.\nGoing right for 1 step(s).\nRobot position is -5, 4.\n\n\n\nAnd now our robot behaves as expected!\n\n\n\n\nNote\n\n\nThe code from this tutorial can be found in the\n\nexamples/robot\n\nfolder.",
            "title": "Robot"
        },
        {
            "location": "/tutorials/robot/#robot-tutorial",
            "text": "In this tutorial we will build a simple robot language to demonstrate\nthe basic workflow when working with textX.",
            "title": "Robot tutorial"
        },
        {
            "location": "/tutorials/robot/#robot-language",
            "text": "When building a DSL we should first do a domain analysis, to see what concepts\ndo we have and what are their relationships and constraints. In the following\nparagraph a short analysis is done. Important concepts are emphasized.  In this case we want an imperative language that should define robot movement on\nthe imaginary grid.  Robot should  move  in four base  direction . We will\ncall that direction  up, down, left  and  right  (you could use north,\nsouth, west and east if you like).  Additionally, we shall have a robot\ncoordinate given in x, y  position .  For simplicity our robot can move in\ndiscrete  steps . In each movement robot can move by 1 or more steps but in\nthe same direction. Coordinate is given as a pair of integer numbers. Robot will\nhave an  initial position . If not given explicitly it is assumed that\nposition is  (0, 0) .  So, lets build a simple robot language.",
            "title": "Robot language"
        },
        {
            "location": "/tutorials/robot/#grammar",
            "text": "First we need to define a grammar for the language. In textX the grammar will\nalso define a meta-model (a.k.a. abstract syntax) for the language which can be\nvisualized and be used as a part of the documentation.  Usually we start by outlining some program in the language we are building.  Here is an example of  program  on robot language:  begin\n    initial 3, 1\n    up 4\n    left 9\n    down\n    right 1\nend  We have  begin  and  end  keywords that define the beginning and end of the\nprogram. In this case we could do without these keywords but lets have it to\nmake it more interesting.  In between those two keywords we have a sequence of instruction. First\ninstruction will position our robot at coordinate  (3, 1) . After that robot will\nmove  up 4 steps ,  left 9 steps ,  down 1 step  (1 step is default) and finally  1\nstep to the right .  Lets start with grammar definition. We shall start in a top-down manner so lets\nfirst define a program as a whole.  Program:\n  'begin'\n    commands*=Command\n  'end'\n;  Here we see that our program is defined with sequence of:   string match ( 'begin' ),  zero or more assignment to  commands  attribute,  string match ( 'end' ).   String matches will require literal strings given at the begin and end of\nprogram. If this is not satisfied a syntax error will be raised. This whole rule\n( Program ) will create a class with the same name in the meta-model. Each\nprogram will be an instance of this class.  commands  assignment will result in\na python attribute  commands  on the instance of  Program  class. This attribute\nwill be of Python  list  type (because  *=  assignment is used).  Each element\nof this list will be a specific command.  Now, we see that we have different types of commands. First command has two\nparameters and it defines the robot initial position. Other commands has one or\nzero parameters and define the robot movement.  To state that some textX rule is specialised in 2 or more rules we use an\nabstract rule. For  Command  we shall define two specializations: InitialCommand  and  MoveCommand  like this:  Command:\n  InitialCommand | MoveCommand\n;  Abstract rule is given as ordered choice of other rules. This can be read as Each command is either a InitialCommand or MoveCommand .  Lets now define command for setting initial position.  InitialCommand:\n  'initial' x=INT ',' y=INT\n;  This rule specifies a class  InitialCommand  in the meta-model. Each initial\nposition command will be an instance of this class.  So, this command should start with the keyword  initial  after which we give an\ninteger number (base type rule  INT  - this number will be available as\nattribute  x  on the  InitialCommand  instance), than a separator  ,  is\nrequired after which we have  y  coordinate as integer number (this will be\navailable as attribute  y ). Using base type rule  INT  matched number from\ninput string will be automatically converted to python type  int .  Now, lets define a movement command. We know that this command consists of\ndirection identifier and optional number of steps (if not given the default will\nbe 1).  MoveCommand:\n  direction=Direction (steps=INT)?\n;  So, the movement command model object will have two attributes. direction  attribute will define one of the four possible directions and steps  attribute will be an integer that will hold how many steps a robot\nwill move in given direction. Steps are optional so if not given in the program\nit will still be a correct syntax. Notice, that the default of 1 is not\nspecified in the grammar. The grammar deals with syntax constraints. Additional\nsemantics will be handled later in model/object processors (see below).  Now, the missing part is  Direction  rule referenced from the previous rule.\nThis rule will define what can be written as a direction.  We will define this\nrule like this:  Direction:\n  \"up\"|\"down\"|\"left\"|\"right\"\n;  This kind of rule is called a  match rule . This rule does not result in a new\nobject. It consists of ordered choice of simple matches (string, regex), base\ntype rules (INT, STRING, BOOL...) and/or other match rule references.  The result of this match will be assigned to the attribute from which it was\nreferenced. If base type was used it will be converted in a proper python type.\nIf not, it will be a python string that will contain the text that was matched\nfrom the input.  In this case a one of 4 words will be matched and that string will be assigned\nto the  direction  attribute of the  MoveCommand  instance.  The final touch to the grammar is a definition of the comment rule. We want to\ncomment our robot code, right?  In textX a special rule called  Comment  is used for that purpose.\nLets define a C-style single line comments.  Comment:\n  /\\/\\/.*$/\n;  Our grammar is done. Save it in  robot.tx  file. The content of this file should\nnow be:  Program:\n  'begin'\n    commands*=Command\n  'end'\n;\n\nCommand:\n  InitialCommand | MoveCommand\n;\n\nInitialCommand:\n  'initial' x=INT ',' y=INT\n;\n\nMoveCommand:\n  direction=Direction (steps=INT)?\n;\n\nDirection:\n  \"up\"|\"down\"|\"left\"|\"right\"\n;\n\nComment:\n  /\\/\\/.*$/\n;  Notice that we have not constrained initial position command to be specified\njust once on the beginning of the program. This basically means that this\ncommand can be given multiple times throughout the program. I will leave as an\nexercise to the reader to implement this constraint.",
            "title": "Grammar"
        },
        {
            "location": "/tutorials/robot/#instantiating-meta-model",
            "text": "In order to parse our models we first need to construct a meta-model. A\ntextX meta-model is a Python object that contains all classes that can be\ninstantiated in our model. For each grammar rule a class is created.\nAdditionally, meta-model contains a parser that knows how to parse input\nstrings. From parsed input (parse tree) meta-model will create a model.  Meta-models are created from our grammar description, in this case robot.tx  file:  from textx.metamodel import metamodel_from_file\nrobot_mm = metamodel_from_file('robot.tx')  Next step during language design is meta-model visualization. It is usually\neasier to comprehend our language if rendered graphically. To do so we use\nexcellent  GraphViz  software package and its DSL for\ngraph specification called  dot . It is a textual language for visual graph\ndefinition.  Lets export our meta-model to dot language.  from textx.export import metamodel_export\nmetamodel_export(robot_mm, 'robot_meta.dot')  First parameter is our meta-model object while the second is an output dot\nfilename.  dot  file can be opened with dot viewer (there are many to choose from) or\ntransformed with  dot  tool to raster or vector graphics.  For example:  dot -Tpng robot_meta.dot -O robot_meta.png  This command will create  png  image out of  dot  file.    Note  This meta-model can be used to parse multiple models.",
            "title": "Instantiating meta-model"
        },
        {
            "location": "/tutorials/robot/#instantiating-model",
            "text": "Now, when we have our meta-model we can parse models from strings or external\ntextual files.  robot_model = robot_mm.model_from_file('program.rbt')  This command will parse file  program.rbt  and constructs our robot model.\nIn this file does not match our language a syntax error will be raised on the\nfirst error encountered.  In the same manner as meta-model visualization we can visualize our model too.  from textx.export import model_export\nmodel_export(robot_model, 'program.dot')  This will create  program.dot  file that can be visualized using proper viewer\nor transformed to image.  dot -Tpng program.dot -O program.png  For the robot program above we should get an image like this:",
            "title": "Instantiating model"
        },
        {
            "location": "/tutorials/robot/#interpreting-model",
            "text": "When we have successfully parsed and loaded our model/program (or mogram or\nprodel ;) ) we can do various stuff. Usually what would you like to do is to\ntranslate your program to some other language (Java, Python, C#, Ruby,...) or\nyou could build an interpreter that will evaluate/interpret your model directly.\nOr you could analyse your model, extract informations from it etc. It is up to\nyou to decide.  We will show here how to build a simple interpreter that will start the robot\nfrom the initial position and print the position of the robot after each\ncommand.  Lets imagine that we have a robot that understands our language.  class Robot(object):\n\n  def __init__(self):\n    # Initial position is (0,0)\n    self.x = 0\n    self.y = 0\n\n  def __str__(self):\n    return \"Robot position is {}, {}.\".format(self.x, self.y)  Now, our robot will have an  interpret  method that accepts our robot model and\nruns it. At each step this method will update the robot position and print it.  def interpret(self, model):\n\n    # model is an instance of Program\n    for c in model.commands:\n\n        if c.__class__.__name__ == \"InitialCommand\":\n            print(\"Setting position to: {}, {}\".format(c.x, c.y))\n            self.x = c.x\n            self.y = c.y\n        else:\n            dir = c.direction\n            print(\"Going {} for {} step(s).\".format(dir, c.steps))\n\n            move = {\n                \"up\": (0, 1),\n                \"down\": (0, -1),\n                \"left\": (-1, 0),\n                \"right\": (1, 0)\n            }[dir]\n\n            # Calculate new robot position\n            self.x += c.steps * move[0]\n            self.y += c.steps * move[1]\n\n        print(self)  Now lets give our  robot_model  to  Robot  instance and see what happens.  robot = Robot()\nrobot.interpret(robot_model)  You should get this output:  Setting position to: 3, 1\nRobot position is 3, 1.\nGoing up for 4 step(s).\nRobot position is 3, 5.\nGoing left for 9 step(s).\nRobot position is -6, 5.\nGoing down for 0 step(s).\nRobot position is -6, 5.\nGoing right for 1 step(s).\nRobot position is -5, 5.  It is  almost  correct. We can see that down movement is for 0 steps because we\nhave not defined the steps for  down  command and haven't done anything yet to\nimplement default of 1.  The best way to implement default value for step is to use so called  object\nprocessor  for  MoveCommand .\nObject processor is a callable that gets called whenever textX parses and\ninstantiates an object of particular class. Use  register_obj_processors \nmethod on meta-model to register callables/processors for classes your wish to\nprocess in some way immediately after instantiation.  Lets define our processor for  MoveCommand .  def move_command_processor(move_cmd):\n\n  # If steps is not given, set it do default 1 value.\n  if move_cmd.steps == 0:\n    move_cmd.steps = 1  Now, register this processor on meta-model. After meta-model construction add a\nline for registration.  robot_mm.register_obj_processors({'MoveCommand': move_command_processor})  register_obj_processors  accepts a dictionary keyed by class name. The\nvalues are callables that should handle instances of the given class.  If you run robot interpreter again you will get output like this:  Setting position to: 3, 1\nRobot position is 3, 1.\nGoing up for 4 step(s).\nRobot position is 3, 5.\nGoing left for 9 step(s).\nRobot position is -6, 5.\nGoing down for 1 step(s).\nRobot position is -6, 4.\nGoing right for 1 step(s).\nRobot position is -5, 4.  And now our robot behaves as expected!   Note  The code from this tutorial can be found in the examples/robot \nfolder.",
            "title": "Interpreting model"
        },
        {
            "location": "/tutorials/entity/",
            "text": "Entity tutorial\n\n\nA tutorial for building ER-like language and generating Java code.\n\n\n\n\n\n\nTODO\n\n\nWill be done soon. In the meantime see \nEntity example\n.",
            "title": "Entity"
        },
        {
            "location": "/tutorials/entity/#entity-tutorial",
            "text": "A tutorial for building ER-like language and generating Java code.    TODO  Will be done soon. In the meantime see  Entity example .",
            "title": "Entity tutorial"
        },
        {
            "location": "/about/discuss/",
            "text": "Discuss, ask questions\n\n\nPlease use \ndiscussion\nforum\n for general\ndiscussions.\n\n\nFor bug reports or suggestions please use \ngithub issue\ntracker\n.\n\n\nIf you have some specific question on textX usage please use\n\nstackoverflow\n.  Just make sure to tag your question\nwith \ntextx\n.",
            "title": "Discuss"
        },
        {
            "location": "/about/discuss/#discuss-ask-questions",
            "text": "Please use  discussion\nforum  for general\ndiscussions.  For bug reports or suggestions please use  github issue\ntracker .  If you have some specific question on textX usage please use stackoverflow .  Just make sure to tag your question\nwith  textx .",
            "title": "Discuss, ask questions"
        },
        {
            "location": "/about/contributing/",
            "text": "Contributing\n\n\ntextX is open for contributions. You can contribute code, documentation, tests,\nbug reports.  If you plan to make a contribution it would be great if you first\nannounce that on the discussion forum.\n\n\nFor bug reports please use \ngithub issue\ntracker\n.\n\n\nFor code/doc/test contributions do the following:\n\n\n\n\nFork the \nproject on github\n.\n\n\nClone your fork.\n\n\nMake a branch for the new feature and switch to it.\n\n\nMake one or more commits.\n\n\nPush your branch to github.\n\n\nMake a pull request. I will look at the changes and if everything is ok I will pull it in.\n\n\n\n\n\n\nNote\n\n\nFor code contributions please try to adhere to the \nPEP-8\nguidelines\n.  Although I am not\nstrict in that regard it is useful to have a common ground for coding style.\nTo make things easier use tools for code checking (PyLint, PyFlakes, pep8\netc.).",
            "title": "Contributing"
        },
        {
            "location": "/about/contributing/#contributing",
            "text": "textX is open for contributions. You can contribute code, documentation, tests,\nbug reports.  If you plan to make a contribution it would be great if you first\nannounce that on the discussion forum.  For bug reports please use  github issue\ntracker .  For code/doc/test contributions do the following:   Fork the  project on github .  Clone your fork.  Make a branch for the new feature and switch to it.  Make one or more commits.  Push your branch to github.  Make a pull request. I will look at the changes and if everything is ok I will pull it in.    Note  For code contributions please try to adhere to the  PEP-8\nguidelines .  Although I am not\nstrict in that regard it is useful to have a common ground for coding style.\nTo make things easier use tools for code checking (PyLint, PyFlakes, pep8\netc.).",
            "title": "Contributing"
        },
        {
            "location": "/about/license/",
            "text": "textX is distributed under the terms of MIT license.\n\n\nCopyright (c) 2014-2015 Igor R. Dejanovi\u0107 \n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.",
            "title": "License"
        }
    ]
}